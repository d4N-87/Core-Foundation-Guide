{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"lang":1,"posts":2,"postIndex":150},"en",[3,11,16,21,26,31,36,44,49,54,59,64,69,74,82,87,92,100,105,110,115,120,125,130,135,140,145],{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":7,"title":8,"excerpt":9,"plainExcerpt":10},"advanced-topics","Advanced Topics","cyan","attention","Attention: The Focusing Mechanism","\u003Cp>\u003Cstrong>Attention\u003C/strong> (or \u003Cem>Self-Attention\u003C/em>) is the computational mechanism at the heart of the \u003Cstrong>Transformer\u003C/strong> architecture, which has revolutionized both lan...\u003C/p>\n","Attention (or Self-Attention) is the computational mechanism at the heart of the Transformer architecture, which has revolutionized both lan...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":12,"title":13,"excerpt":14,"plainExcerpt":15},"dit","DiT: Diffusion Transformers","\u003Cp>A \u003Cstrong>DiT (Diffusion Transformer)\u003C/strong> is a new architecture for diffusion models that \u003Cstrong>replaces the traditional UNet with a Transformer\u003C/strong>. [1] It is an e...\u003C/p>\n","A DiT (Diffusion Transformer) is a new architecture for diffusion models that replaces the traditional UNet with a Transformer. [1] It is an e...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":17,"title":18,"excerpt":19,"plainExcerpt":20},"gguf","GGUF: Quantization for CPU and GPU","\u003Cp>\u003Cstrong>GGUF (Georgi Gerganov Universal Format)\u003C/strong> is a file format designed to contain \u003Cstrong>quantized\u003C/strong> neural models, that is, converted into very low-precisi...\u003C/p>\n","GGUF (Georgi Gerganov Universal Format) is a file format designed to contain quantized neural models, that is, converted into very low-precisi...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":22,"title":23,"excerpt":24,"plainExcerpt":25},"llm","LLM: Large Language Models","\u003Cp>An \u003Cstrong>LLM (Large Language Model)\u003C/strong> is a type of neural network trained on massive amounts of text data (books, articles, code, conversations) with the ...\u003C/p>\n","An LLM (Large Language Model) is a type of neural network trained on massive amounts of text data (books, articles, code, conversations) with the ...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":27,"title":28,"excerpt":29,"plainExcerpt":30},"precision","Precision: FP32, FP16, FP8, FP4 and the Role of the GPU","\u003Cp>The \u003Cstrong>precision\u003C/strong> of a model refers to the numerical format used to store its &quot;weights&quot;. These weights are real numbers, and computers represent them ...\u003C/p>\n","The precision of a model refers to the numerical format used to store its \"weights\". These weights are real numbers, and computers represent them ...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":32,"title":33,"excerpt":34,"plainExcerpt":35},"tokens","Tokens: The Building Blocks of Language","\u003Cp>\u003Cstrong>Tokens\u003C/strong> are the fundamental units into which a text is broken down before being processed by a language model like CLIP. [1] They are the &quot;building...\u003C/p>\n","Tokens are the fundamental units into which a text is broken down before being processed by a language model like CLIP. [1] They are the \"building...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":40,"title":41,"excerpt":42,"plainExcerpt":43},"core-concepts","Core Concepts","amber","cfg","CFG: The Guidance Scale","\u003Cp>The \u003Cstrong>CFG (Classifier-Free Guidance) Scale\u003C/strong> is one of the most powerful parameters at your disposal. In simple terms, it&#39;s a knob that controls **how...\u003C/p>\n","The CFG (Classifier-Free Guidance) Scale is one of the most powerful parameters at your disposal. In simple terms, it's a knob that controls how...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":45,"title":46,"excerpt":47,"plainExcerpt":48},"denoise","Denoise: The Strength of Transformation","\u003Cp>The \u003Cstrong>Denoise\u003C/strong> (or \u003Cem>denoising strength\u003C/em>) parameter is a knob that controls \u003Cstrong>how much of the starting image should be transformed\u003C/strong> during the genera...\u003C/p>\n","The Denoise (or denoising strength) parameter is a knob that controls how much of the starting image should be transformed during the genera...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":50,"title":51,"excerpt":52,"plainExcerpt":53},"prompt","Prompt: Dialoguing with the AI","\u003Cp>The \u003Cstrong>Prompt\u003C/strong> is the textual instruction you provide to the model to describe the image you want to create. It&#39;s the most direct way to dialogue with...\u003C/p>\n","The Prompt is the textual instruction you provide to the model to describe the image you want to create. It's the most direct way to dialogue with...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":55,"title":56,"excerpt":57,"plainExcerpt":58},"sampler","Sampler: The Denoising Technique","\u003Cp>The \u003Cstrong>Sampler\u003C/strong> is the algorithm that actually performs the &quot;denoising&quot; process at each step. [1] If the AI model is the brain that predicts the noise...\u003C/p>\n","The Sampler is the algorithm that actually performs the \"denoising\" process at each step. [1] If the AI model is the brain that predicts the noise...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":60,"title":61,"excerpt":62,"plainExcerpt":63},"scheduler","Scheduler: The Denoising Plan","\u003Cp>The \u003Cstrong>Scheduler\u003C/strong> is the algorithm that defines the \u003Cstrong>strategy\u003C/strong> and \u003Cstrong>pace\u003C/strong> of the denoising process. [1] If the Sampler is the \u003Cem>technique\u003C/em> with whi...\u003C/p>\n","The Scheduler is the algorithm that defines the strategy and pace of the denoising process. [1] If the Sampler is the technique with whi...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":65,"title":66,"excerpt":67,"plainExcerpt":68},"seed","Seed: The Control of Randomness","\u003Cp>The \u003Cstrong>Seed\u003C/strong> is a number that initializes the state of randomness for the generation of an image. Think of it as the \u003Cstrong>unique identification code\u003C/strong> of...\u003C/p>\n","The Seed is a number that initializes the state of randomness for the generation of an image. Think of it as the unique identification code of...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":70,"title":71,"excerpt":72,"plainExcerpt":73},"steps","Steps: The Sampling Steps","\u003Cp>\u003Cstrong>Steps\u003C/strong> (or sampling steps) indicate how many times the model &quot;refines&quot; the image starting from pure noise. It is one of the most important paramete...\u003C/p>\n","Steps (or sampling steps) indicate how many times the model \"refines\" the image starting from pure noise. It is one of the most important paramete...",{"lang":1,"categorySlug":75,"categoryName":76,"categoryColor":77,"slug":78,"title":79,"excerpt":80,"plainExcerpt":81},"fundamentals","Fundamentals","sky","deep_learning","Deep Learning: The Deep Learning","\u003Cp>\u003Cstrong>Deep Learning\u003C/strong> is a subcategory of Machine Learning based on \u003Cstrong>Deep Artificial Neural Networks\u003C/strong>, that is, neural networks with many hidden layers ...\u003C/p>\n","Deep Learning is a subcategory of Machine Learning based on Deep Artificial Neural Networks, that is, neural networks with many hidden layers ...",{"lang":1,"categorySlug":75,"categoryName":76,"categoryColor":77,"slug":83,"title":84,"excerpt":85,"plainExcerpt":86},"inference","Inference: Using the Trained Model","\u003Cp>\u003Cstrong>Inference\u003C/strong> is the process of \u003Cstrong>using an already trained neural network\u003C/strong> to make predictions on new and unseen data. [1]\u003C/p>\n\u003Cp>If \u003Cstrong>training\u003C/strong> is the &quot;s...\u003C/p>\n","Inference is the process of using an already trained neural network to make predictions on new and unseen data. [1]\n\nIf training is the \"s...",{"lang":1,"categorySlug":75,"categoryName":76,"categoryColor":77,"slug":88,"title":89,"excerpt":90,"plainExcerpt":91},"neural_network","Neural Network: The Artificial Brain","\u003Cp>An \u003Cstrong>Artificial Neural Network\u003C/strong> is a computational model inspired by the structure and functioning of the human brain. [1] It is the fundamental buil...\u003C/p>\n","An Artificial Neural Network is a computational model inspired by the structure and functioning of the human brain. [1] It is the fundamental buil...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":96,"title":97,"excerpt":98,"plainExcerpt":99},"system-anatomy","System Anatomy","teal","checkpoint","Checkpoint: The Brain of the Model","\u003Cp>The term \u003Cstrong>Checkpoint\u003C/strong> (or \u003Cem>Model\u003C/em>) refers to the files that contain the &quot;weights&quot; of the neural network, that is, the \u003Cstrong>trained brain\u003C/strong> of the artif...\u003C/p>\n","The term Checkpoint (or Model) refers to the files that contain the \"weights\" of the neural network, that is, the trained brain of the artif...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":101,"title":102,"excerpt":103,"plainExcerpt":104},"clip","CLIP Text Encoder: The Prompt Translator","\u003Cp>\u003Cstrong>CLIP (Contrastive Language-Image Pre-training)\u003C/strong> is a neural model developed by OpenAI that has revolutionized how AIs &quot;understand&quot; the relationship...\u003C/p>\n","CLIP (Contrastive Language-Image Pre-training) is a neural model developed by OpenAI that has revolutionized how AIs \"understand\" the relationship...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":106,"title":107,"excerpt":108,"plainExcerpt":109},"conditioning","Conditioning: The Instructions for the UNet","\u003Cp>\u003Cstrong>Conditioning\u003C/strong> is the technical term that describes the \u003Cstrong>guidance data\u003C/strong> that is provided to the UNet to influence and control the image generation...\u003C/p>\n","Conditioning is the technical term that describes the guidance data that is provided to the UNet to influence and control the image generation...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":111,"title":112,"excerpt":113,"plainExcerpt":114},"controlnet","ControlNet: Guiding the AI with Images","\u003Cp>\u003Cstrong>ControlNet\u003C/strong> is a neural network architecture that allows \u003Cstrong>conditioning and controlling diffusion models using a visual input\u003C/strong>, such as an image o...\u003C/p>\n","ControlNet is a neural network architecture that allows conditioning and controlling diffusion models using a visual input, such as an image o...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":116,"title":117,"excerpt":118,"plainExcerpt":119},"embedding","Embedding (Textual Inversion): Teaching New Concepts","\u003Cp>An \u003Cstrong>Embedding\u003C/strong>, also known as \u003Cstrong>Textual Inversion\u003C/strong>, is a small file that teaches the model a \u003Cstrong>new visual concept\u003C/strong> by associating it with a specif...\u003C/p>\n","An Embedding, also known as Textual Inversion, is a small file that teaches the model a new visual concept by associating it with a specif...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":121,"title":122,"excerpt":123,"plainExcerpt":124},"inpaint","Inpainting & Outpainting: Modifying and Extending Images","\u003Cp>\u003Cstrong>Inpainting\u003C/strong> and \u003Cstrong>Outpainting\u003C/strong> are two powerful techniques that use diffusion models not to create an image from scratch, but to **modify or exten...\u003C/p>\n","Inpainting and Outpainting are two powerful techniques that use diffusion models not to create an image from scratch, but to modify or exten...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":126,"title":127,"excerpt":128,"plainExcerpt":129},"latent","Latent Space: The Compressed World of Images","\u003Cp>The \u003Cstrong>Latent Space\u003C/strong> is a compressed and low-resolution representation of an image. It is an intermediate &quot;world&quot; in which diffusion models like Stabl...\u003C/p>\n","The Latent Space is a compressed and low-resolution representation of an image. It is an intermediate \"world\" in which diffusion models like Stabl...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":131,"title":132,"excerpt":133,"plainExcerpt":134},"lora","LoRa: Lightweight Style Modifiers","\u003Cp>A \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> is a small file that applies targeted modifications to a full checkpoint model, without permanently altering it. [1] ...\u003C/p>\n","A LoRa (Low-Rank Adaptation) is a small file that applies targeted modifications to a full checkpoint model, without permanently altering it. [1] ...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":136,"title":137,"excerpt":138,"plainExcerpt":139},"segmentation","Segmentation: Understanding the Scene","\u003Cp>\u003Cstrong>Image Segmentation\u003C/strong> is a Computer Vision process that consists of \u003Cstrong>partitioning an image into multiple segments or regions\u003C/strong>, associating each pix...\u003C/p>\n","Image Segmentation is a Computer Vision process that consists of partitioning an image into multiple segments or regions, associating each pix...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":141,"title":142,"excerpt":143,"plainExcerpt":144},"unet","UNet: The Heart of Denoising","\u003Cp>The \u003Cstrong>UNet\u003C/strong> is the central and most important component of a diffusion model like Stable Diffusion. It is the neural network that learns to **progres...\u003C/p>\n","The UNet is the central and most important component of a diffusion model like Stable Diffusion. It is the neural network that learns to progres...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":146,"title":147,"excerpt":148,"plainExcerpt":149},"vae","VAE: The Visual Decoder","\u003Cp>The \u003Cstrong>VAE (Variational Autoencoder)\u003C/strong> is the final decoder of your system. [1, 2]\u003C/p>\n\u003Cp>Imagine that the AI model does not &quot;think&quot; with images, but in an a...\u003C/p>\n","The VAE (Variational Autoencoder) is the final decoder of your system. [1, 2]\n\nImagine that the AI model does not \"think\" with images, but in an a...",[151,156,169,178],{"categoryName":76,"categorySlug":75,"posts":152},[153,154,155],{"title":79,"slug":78},{"title":84,"slug":83},{"title":89,"slug":88},{"categoryName":94,"categorySlug":93,"posts":157},[158,159,160,161,162,163,164,165,166,167,168],{"title":97,"slug":96},{"title":102,"slug":101},{"title":107,"slug":106},{"title":112,"slug":111},{"title":117,"slug":116},{"title":122,"slug":121},{"title":127,"slug":126},{"title":132,"slug":131},{"title":137,"slug":136},{"title":142,"slug":141},{"title":147,"slug":146},{"categoryName":38,"categorySlug":37,"posts":170},[171,172,173,174,175,176,177],{"title":41,"slug":40},{"title":46,"slug":45},{"title":51,"slug":50},{"title":56,"slug":55},{"title":61,"slug":60},{"title":66,"slug":65},{"title":71,"slug":70},{"categoryName":5,"categorySlug":4,"posts":179},[180,181,182,183,184,185],{"title":8,"slug":7},{"title":13,"slug":12},{"title":18,"slug":17},{"title":23,"slug":22},{"title":28,"slug":27},{"title":33,"slug":32}],"uses":{"params":["lang"]}}]}
