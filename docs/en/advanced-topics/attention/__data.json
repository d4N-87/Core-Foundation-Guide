{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":18,"seo":104,"textContent":105},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"en","advanced-topics","Advanced Topics","cyan","attention","Attention: The Focusing Mechanism","\u003Cp>\u003Cstrong>Attention\u003C/strong> (or \u003Cem>Self-Attention\u003C/em>) is the computational mechanism at the heart of the \u003Cstrong>Transformer\u003C/strong> architecture, which has revolutionized both lan...\u003C/p>\n","Attention (or Self-Attention) is the computational mechanism at the heart of the Transformer architecture, which has revolutionized both lan...","\u003Cp>\u003Cstrong>Attention\u003C/strong> (or \u003Cem>Self-Attention\u003C/em>) is the computational mechanism at the heart of the \u003Cstrong>Transformer\u003C/strong> architecture, which has revolutionized both language models (LLMs) and, more recently, diffusion models (DiTs). [1]\u003C/p>\n\u003Cp>In simple terms, Attention allows a model to \u003Cstrong>dynamically weigh the importance of different parts of an input\u003C/strong> (like words in a sentence or patches in an image) to understand the context and the relationships between them. [2]\u003C/p>\n\u003Ch3>How Does It Work (Conceptually)?\u003C/h3>\n\u003Cp>Imagine reading the sentence: \u003Ccode>A red cat chases a gray mouse\u003C/code>.\nWhen the model processes the word &quot;red&quot;, the Attention mechanism allows it to understand that &quot;red&quot; is strongly connected to &quot;cat&quot; and not to &quot;mouse&quot;. In practice, for each word, Attention calculates an &quot;attention score&quot; with respect to all other words in the sentence, &quot;focusing&quot; on the most important relationships. [2]\u003C/p>\n\u003Cp>This is fundamental for resolving ambiguities and understanding the nuances of language.\u003C/p>\n\u003Ch3>Attention in Image Generation\u003C/h3>\n\u003Cp>The Attention mechanism is crucial at two points in our workflow:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>In the CLIP Text Encoder:\u003C/strong>\nWhen CLIP processes our prompt, Attention is what allows it to understand that in \u003Ccode>an astronaut on a horse\u003C/code>, it&#39;s the astronaut who should be on the horse. It&#39;s also the mechanism that is influenced when we increase the weight of a word with the syntax \u003Ccode>(word:1.2)\u003C/code>, telling it to &quot;pay more attention&quot; to that concept.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>In Diffusion Transformers (DiTs):\u003C/strong>\nIn models like Stable Diffusion 3, Attention is not only applied to the text but also to the &quot;visual tokens&quot; (the image patches). This allows the model to create complex relationships between different parts of the image, drastically improving coherence and composition. For example, it can ensure that a reflection in a mirror correctly corresponds to the reflected object.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Cp>In summary, Attention is the technology that has allowed models to move from a simple &quot;association&quot; of words to a true &quot;understanding&quot; of context and relationships, both in text and in images.\u003C/p>\n",[12,15],{"text":13,"url":14},"Paper 'Attention Is All You Need' that introduced the Transformer","https://arxiv.org/abs/1706.03762",{"text":16,"url":17},"Illustrated explanation of the Attention mechanism","https://jalammar.github.io/visualizing-neural-machine-translation-self-attention-visualizations-for-transformer-models/",{"it":19,"en":34,"fr":49,"es":63,"de":78,"pt":93},{"category":20,"connections":21,"backToHub":22,"noPostsFound":23,"pageTitleCategory":20,"initializing":24,"backToArticles":25,"sources":26,"searchPlaceholder":27,"showMap":28,"hideMap":29,"listenToArticle":30,"playing":31,"paused":32,"voice":33},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":35,"connections":36,"backToHub":37,"noPostsFound":38,"pageTitleCategory":35,"initializing":39,"backToArticles":40,"sources":41,"searchPlaceholder":42,"showMap":43,"hideMap":44,"listenToArticle":45,"playing":46,"paused":47,"voice":48},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":50,"connections":51,"backToHub":52,"noPostsFound":53,"pageTitleCategory":50,"initializing":54,"backToArticles":55,"sources":41,"searchPlaceholder":56,"showMap":57,"hideMap":58,"listenToArticle":59,"playing":60,"paused":61,"voice":62},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":64,"connections":65,"backToHub":66,"noPostsFound":67,"pageTitleCategory":64,"initializing":68,"backToArticles":69,"sources":70,"searchPlaceholder":71,"showMap":72,"hideMap":73,"listenToArticle":74,"playing":75,"paused":76,"voice":77},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":79,"connections":80,"backToHub":81,"noPostsFound":82,"pageTitleCategory":79,"initializing":83,"backToArticles":84,"sources":85,"searchPlaceholder":86,"showMap":87,"hideMap":88,"listenToArticle":89,"playing":90,"paused":91,"voice":92},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":20,"connections":94,"backToHub":95,"noPostsFound":96,"pageTitleCategory":20,"initializing":68,"backToArticles":97,"sources":98,"searchPlaceholder":99,"showMap":100,"hideMap":73,"listenToArticle":101,"playing":102,"paused":103,"voice":77},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"Attention: The Focusing Mechanism. Attention (or Self-Attention) is the computational mechanism at the heart of the Transformer architecture, which has revolutionized both language models (LLMs) and, more recently, diffusion models (DiTs). In simple terms, Attention allows a model to dynamically weigh the importance of different parts of an input (like words in a sentence or patches in an image) to understand the context and the relationships between them. How Does It Work (Conceptually)?; Imagine reading the sentence: `A red cat chases a gray mouse`. When the model processes the word \"red\", the Attention mechanism allows it to understand that \"red\" is strongly connected to \"cat\" and not to \"mouse\". In practice, for each word, Attention calculates an \"attention score\" with respect to all other words in the sentence, \"focusing\" on the most important relationships. This is fundamental for resolving ambiguities and understanding the nuances of language. Attention in Image Generation; The Attention mechanism is crucial at two points in our workflow: 1. In the CLIP Text Encoder: When CLIP processes our prompt, Attention is what allows it to understand that in `an astronaut on a horse`, it's the astronaut who should be on the horse. It's also the mechanism that is influenced when we increase the weight of a word with the syntax `(word:1.2)`, telling it to \"pay more attention\" to that concept. 2. In Diffusion Transformers (DiTs): In models like Stable Diffusion 3, Attention is not only applied to the text but also to the \"visual tokens\" (the image patches). This allows the model to create complex relationships between different parts of the image, drastically improving coherence and composition. For example, it can ensure that a reflection in a mirror correctly corresponds to the reflected object. In summary, Attention is the technology that has allowed models to move from a simple \"association\" of words to a true \"understanding\" of context and relationships, both in text and in images."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
