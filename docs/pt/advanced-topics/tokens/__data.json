{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"pt","advanced-topics","Advanced Topics","cyan","tokens","Tokens: Os Blocos de Construção da Linguagem","\u003Cp>\u003Cstrong>Tokens\u003C/strong> são as unidades fundamentais em que um texto é dividido antes de ser processado por um modelo de linguagem como o CLIP. [1] São os &quot;blocos ...\u003C/p>\n","Tokens são as unidades fundamentais em que um texto é dividido antes de ser processado por um modelo de linguagem como o CLIP. [1] São os \"blocos ...","\u003Cp>\u003Cstrong>Tokens\u003C/strong> são as unidades fundamentais em que um texto é dividido antes de ser processado por um modelo de linguagem como o CLIP. [1] São os &quot;blocos de construção&quot; com os quais o modelo lê e entende nosso prompt.\u003C/p>\n\u003Cp>Um token \u003Cstrong>não é necessariamente uma palavra inteira\u003C/strong>. O processo de \u003Cstrong>Tokenização\u003C/strong> usa um vocabulário predefinido para dividir o texto em pedaços que o modelo conhece. [3]\u003C/p>\n\u003Ch3>Exemplos de Tokenização\u003C/h3>\n\u003Cp>Considere a palavra \u003Ccode>indescritivelmente\u003C/code>. Um tokenizador pode dividi-la em vários tokens que ele conhece:\n\u003Ccode>in\u003C/code> + \u003Ccode>descri\u003C/code> + \u003Ccode>tivel\u003C/code> + \u003Ccode>mente\u003C/code>\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Palavras comuns\u003C/strong> (por exemplo, \u003Ccode>gato\u003C/code>, \u003Ccode>o\u003C/code>, \u003Ccode>um\u003C/code>) são frequentemente um único token.\u003C/li>\n\u003Cli>\u003Cstrong>Palavras complexas ou raras\u003C/strong> são divididas em sub-palavras.\u003C/li>\n\u003Cli>\u003Cstrong>Espaços e pontuação\u003C/strong> são tratados como tokens separados.\u003C/li>\n\u003C/ul>\n\u003Cp>Essa abordagem permite que o modelo lide com um vocabulário virtualmente infinito a partir de um número finito de tokens (geralmente entre 30.000 e 50.000). [1]\u003C/p>\n\u003Ch3>O Limite de Tokens e a Evolução dos Modelos\u003C/h3>\n\u003Cp>Cada Codificador de Texto tem um \u003Cstrong>limite máximo de tokens\u003C/strong> que pode processar em um único &quot;bloco&quot;. Esse limite tem sido, por muito tempo, uma das principais restrições na engenharia de prompts.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cp>\u003Cstrong>Arquiteturas Antigas (por exemplo, Stable Diffusion 1.5, SDXL):\u003C/strong>\nEsses modelos usam Codificadores de Texto (CLIP) com um limite de \u003Cstrong>75 tokens\u003C/strong> por bloco. [3] Se um prompt for mais longo, ele é dividido em vários blocos, mas a compreensão do contexto entre um bloco e outro é muito mais fraca. Isso forçou os usuários a concentrarem os conceitos mais importantes no início do prompt.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Novas Arquiteturas (por exemplo, FLUX.1):\u003C/strong>\nModelos de nova geração, como o \u003Cstrong>FLUX.1\u003C/strong>, são projetados para superar essa limitação. O FLUX.1 usa um Codificador de Texto muito mais poderoso (baseado no T5-XXL) que foi especificamente treinado para entender prompts longos e complexos nativamente. [2] Isso permite uma expressão muito mais natural e detalhada, sem ter que se preocupar com o limite artificial de 75 tokens.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>Entender o conceito de tokens e as limitações de diferentes modelos é fundamental para escrever prompts eficazes e aproveitar ao máximo as capacidades de cada arquitetura.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Introdução à Tokenização - Hugging Face","https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt",{"text":16,"url":17},"Anúncio do modelo FLUX.1 pela Black Forest Labs","https://blackforestlabs.ai/announcing-flux/",{"text":19,"url":20},"Explicação dos Tokens no contexto do Stable Diffusion","https://stable-diffusion-art.com/token/",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"Tokens: Os Blocos de Construção da Linguagem. Tokens são as unidades fundamentais em que um texto é dividido antes de ser processado por um modelo de linguagem como o CLIP. São os \"blocos de construção\" com os quais o modelo lê e entende nosso prompt. Um token não é necessariamente uma palavra inteira. O processo de Tokenização usa um vocabulário predefinido para dividir o texto em pedaços que o modelo conhece. Exemplos de Tokenização; Considere a palavra `indescritivelmente`. Um tokenizador pode dividi-la em vários tokens que ele conhece: `in` + `descri` + `tivel` + `mente` - Palavras comuns (por exemplo, `gato`, `o`, `um`) são frequentemente um único token. - Palavras complexas ou raras são divididas em sub-palavras. - Espaços e pontuação são tratados como tokens separados. Essa abordagem permite que o modelo lide com um vocabulário virtualmente infinito a partir de um número finito de tokens (geralmente entre 30.000 e 50.000). O Limite de Tokens e a Evolução dos Modelos; Cada Codificador de Texto tem um limite máximo de tokens que pode processar em um único \"bloco\". Esse limite tem sido, por muito tempo, uma das principais restrições na engenharia de prompts. - Arquiteturas Antigas (por exemplo, Stable Diffusion 1.5, SDXL): Esses modelos usam Codificadores de Texto (CLIP) com um limite de 75 tokens por bloco. Se um prompt for mais longo, ele é dividido em vários blocos, mas a compreensão do contexto entre um bloco e outro é muito mais fraca. Isso forçou os usuários a concentrarem os conceitos mais importantes no início do prompt. - Novas Arquiteturas (por exemplo, FLUX.1): Modelos de nova geração, como o FLUX.1, são projetados para superar essa limitação. O FLUX.1 usa um Codificador de Texto muito mais poderoso (baseado no T5-XXL) que foi especificamente treinado para entender prompts longos e complexos nativamente. Isso permite uma expressão muito mais natural e detalhada, sem ter que se preocupar com o limite artificial de 75 tokens. Entender o conceito de tokens e as limitações de diferentes modelos é fundamental para escrever prompts eficazes e aproveitar ao máximo as capacidades de cada arquitetura."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
