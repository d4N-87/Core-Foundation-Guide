{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":18,"seo":104,"textContent":105},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"pt","fundamentals","Fundamentals","sky","inference","Inferência: Usando o Modelo Treinado","\u003Cp>A \u003Cstrong>Inferência\u003C/strong> é o processo de \u003Cstrong>usar uma rede neural já treinada\u003C/strong> para fazer previsões sobre dados novos e nunca antes vistos. [1]\u003C/p>\n\u003Cp>Se o **treinam...\u003C/p>\n","A Inferência é o processo de usar uma rede neural já treinada para fazer previsões sobre dados novos e nunca antes vistos. [1]\n\nSe o treinam...","\u003Cp>A \u003Cstrong>Inferência\u003C/strong> é o processo de \u003Cstrong>usar uma rede neural já treinada\u003C/strong> para fazer previsões sobre dados novos e nunca antes vistos. [1]\u003C/p>\n\u003Cp>Se o \u003Cstrong>treinamento\u003C/strong> é a fase de &quot;estudo&quot; em que o modelo aprende com os livros (o conjunto de dados), a \u003Cstrong>inferência\u003C/strong> é o \u003Cstrong>exame final\u003C/strong> em que ele deve aplicar o que aprendeu para responder a novas perguntas. [2]\u003C/p>\n\u003Ch3>O Processo de Inferência na Prática\u003C/h3>\n\u003Cp>Quando geramos uma imagem com o Stable Diffusion, estamos realizando um processo de inferência:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Carregar o Modelo:\u003C/strong> Pegamos um checkpoint (\u003Ccode>.safetensors\u003C/code>), que é o resultado de um longo e caro processo de treinamento.\u003C/li>\n\u003Cli>\u003Cstrong>Fornecer uma Entrada:\u003C/strong> Damos ao modelo novos dados que ele nunca viu durante o estudo (nosso prompt e uma imagem de ruído aleatório).\u003C/li>\n\u003Cli>\u003Cstrong>O Modelo &quot;Infere&quot;:\u003C/strong> A rede neural processa a entrada através de suas camadas, usando os pesos que aprendeu, e produz uma saída (a previsão do ruído a ser removido).\u003C/li>\n\u003Cli>\u003Cstrong>Obtemos uma Saída:\u003C/strong> Repetindo esse processo por um certo número de &quot;passos&quot;, obtemos a imagem final.\u003C/li>\n\u003C/ol>\n\u003Ch3>Inferência vs. Treinamento\u003C/h3>\n\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">Característica\u003C/th>\n\u003Cth align=\"left\">Treinamento\u003C/th>\n\u003Cth align=\"left\">Inferência\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Propósito\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Ensinar o modelo, criar os &quot;pesos&quot;\u003C/td>\n\u003Ctd align=\"left\">Usar o modelo para obter resultados\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Recursos Necessários\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Enormes (muitas GPUs, semanas de tempo)\u003C/td>\n\u003Ctd align=\"left\">Moderados (uma única GPU, segundos/minutos)\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Dados\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Grande conjunto de dados rotulados\u003C/td>\n\u003Ctd align=\"left\">Dados de entrada únicos (por exemplo, um prompt)\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Quem faz?\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Laboratórios de pesquisa, empresas, a comunidade\u003C/td>\n\u003Ctd align=\"left\">O usuário final (nós!)\u003C/td>\n\u003C/tr>\n\u003C/tbody>\u003C/table>\n\u003Cp>Em resumo, toda vez que pressionamos o botão &quot;Gerar&quot;, estamos realizando uma \u003Cstrong>inferência\u003C/strong>.\u003C/p>\n",[12,15],{"text":13,"url":14},"O que é Inferência? - Amazon Web Services","https://aws.amazon.com/it/what-is/inference/",{"text":16,"url":17},"Inferência vs. Treinamento - Google Cloud","https://cloud.google.com/discover/inference-vs-training?hl=it",{"it":19,"en":34,"fr":49,"es":63,"de":78,"pt":93},{"category":20,"connections":21,"backToHub":22,"noPostsFound":23,"pageTitleCategory":20,"initializing":24,"backToArticles":25,"sources":26,"searchPlaceholder":27,"showMap":28,"hideMap":29,"listenToArticle":30,"playing":31,"paused":32,"voice":33},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":35,"connections":36,"backToHub":37,"noPostsFound":38,"pageTitleCategory":35,"initializing":39,"backToArticles":40,"sources":41,"searchPlaceholder":42,"showMap":43,"hideMap":44,"listenToArticle":45,"playing":46,"paused":47,"voice":48},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":50,"connections":51,"backToHub":52,"noPostsFound":53,"pageTitleCategory":50,"initializing":54,"backToArticles":55,"sources":41,"searchPlaceholder":56,"showMap":57,"hideMap":58,"listenToArticle":59,"playing":60,"paused":61,"voice":62},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":64,"connections":65,"backToHub":66,"noPostsFound":67,"pageTitleCategory":64,"initializing":68,"backToArticles":69,"sources":70,"searchPlaceholder":71,"showMap":72,"hideMap":73,"listenToArticle":74,"playing":75,"paused":76,"voice":77},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":79,"connections":80,"backToHub":81,"noPostsFound":82,"pageTitleCategory":79,"initializing":83,"backToArticles":84,"sources":85,"searchPlaceholder":86,"showMap":87,"hideMap":88,"listenToArticle":89,"playing":90,"paused":91,"voice":92},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":20,"connections":94,"backToHub":95,"noPostsFound":96,"pageTitleCategory":20,"initializing":68,"backToArticles":97,"sources":98,"searchPlaceholder":99,"showMap":100,"hideMap":73,"listenToArticle":101,"playing":102,"paused":103,"voice":77},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"Inferência: Usando o Modelo Treinado. A Inferência é o processo de usar uma rede neural já treinada para fazer previsões sobre dados novos e nunca antes vistos. Se o treinamento é a fase de \"estudo\" em que o modelo aprende com os livros (o conjunto de dados), a inferência é o exame final em que ele deve aplicar o que aprendeu para responder a novas perguntas. O Processo de Inferência na Prática; Quando geramos uma imagem com o Stable Diffusion, estamos realizando um processo de inferência: 1. Carregar o Modelo: Pegamos um checkpoint (`.safetensors`), que é o resultado de um longo e caro processo de treinamento. 2. Fornecer uma Entrada: Damos ao modelo novos dados que ele nunca viu durante o estudo (nosso prompt e uma imagem de ruído aleatório). 3. O Modelo \"Infere\": A rede neural processa a entrada através de suas camadas, usando os pesos que aprendeu, e produz uma saída (a previsão do ruído a ser removido). 4. Obtemos uma Saída: Repetindo esse processo por um certo número de \"passos\", obtemos a imagem final. Inferência vs. Treinamento; | Característica | Treinamento | Inferência | | : | :--- | | Propósito | Ensinar o modelo, criar os \"pesos\" | Usar o modelo para obter resultados | | Recursos Necessários | Enormes (muitas GPUs, semanas de tempo) | Moderados (uma única GPU, segundos/minutos) | | Dados | Grande conjunto de dados rotulados | Dados de entrada únicos (por exemplo, um prompt) | | Quem faz? | Laboratórios de pesquisa, empresas, a comunidade | O usuário final (nós!) | Em resumo, toda vez que pressionamos o botão \"Gerar\", estamos realizando uma inferência."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
