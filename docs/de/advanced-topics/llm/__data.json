{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"de","advanced-topics","Advanced Topics","cyan","llm","LLM: Große Sprachmodelle","\u003Cp>Ein \u003Cstrong>LLM (Large Language Model)\u003C/strong>, oder Großes Sprachmodell, ist eine Art von neuronalem Netzwerk, das auf riesigen Mengen von Textdaten (Bücher, Art...\u003C/p>\n","Ein LLM (Large Language Model), oder Großes Sprachmodell, ist eine Art von neuronalem Netzwerk, das auf riesigen Mengen von Textdaten (Bücher, Art...","\u003Cp>Ein \u003Cstrong>LLM (Large Language Model)\u003C/strong>, oder Großes Sprachmodell, ist eine Art von neuronalem Netzwerk, das auf riesigen Mengen von Textdaten (Bücher, Artikel, Code, Konversationen) trainiert wurde, mit dem Ziel, \u003Cstrong>menschliche Sprache\u003C/strong> kohärent und kontextuell relevant zu \u003Cstrong>verstehen und zu generieren\u003C/strong>. [2, 3]\u003C/p>\n\u003Cp>Berühmte Beispiele für LLMs sind die \u003Cstrong>GPT\u003C/strong>-Serie von OpenAI (die Grundlage von ChatGPT), \u003Cstrong>Llama\u003C/strong> von Meta, \u003Cstrong>Gemini\u003C/strong> von Google und \u003Cstrong>Claude\u003C/strong> von Anthropic.\u003C/p>\n\u003Ch3>Wie funktionieren sie konzeptionell?\u003C/h3>\n\u003Cp>Im Kern ist ein LLM eine leistungsstarke \u003Cstrong>Engine zur Vorhersage des nächsten Wortes\u003C/strong>. [3] Wenn ihm ein Eingabetext (ein &quot;Prompt&quot;) gegeben wird, berechnet das Modell die Wahrscheinlichkeit, welches Wort (oder &quot;Token&quot;) als nächstes kommen sollte, basierend auf den sprachlichen Mustern, die es während des Trainings gelernt hat. Durch die tausendfache Wiederholung dieses Prozesses ist es in der Lage, Sätze, Absätze und ganze Dokumente zu generieren.\u003C/p>\n\u003Ch3>Die Schlüsselarchitektur: der Transformer\u003C/h3>\n\u003Cp>Die LLM-Revolution wurde durch die Erfindung der \u003Cstrong>Transformer\u003C/strong>-Architektur im Jahr 2017 ermöglicht. [1] Ihre grundlegende Komponente, der \u003Cstrong>Attention\u003C/strong>-Mechanismus, ermöglicht es dem Modell, die Bedeutung verschiedener Wörter im Eingabetext zu gewichten und so Beziehungen und Kontext auch über große Entfernungen hinweg zu verstehen. Das ist es, was LLMs ihre außergewöhnliche Fähigkeit verleiht, Konversationen zu folgen, Sprachen zu übersetzen und Code zu schreiben.\u003C/p>\n\u003Ch3>LLMs und Bilderzeugung\u003C/h3>\n\u003Cp>Obwohl sie auf Text spezialisiert sind, sind LLMs auf zwei Arten eng mit der Welt der Bilderzeugung verbunden:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Der Text-Encoder (CLIP):\u003C/strong> Die Komponente, die unsere Prompts in Diffusionsmodellen interpretiert, ist im Grunde genommen eine Art von Sprachmodell, das auf der Transformer-Architektur basiert. [1]\u003C/li>\n\u003Cli>\u003Cstrong>Hybrid-Architekturen (DiT):\u003C/strong> Innovationen im Bereich der LLMs, insbesondere die Transformer-Architektur, werden auch für die Bilderzeugung übernommen, was zur Entstehung neuer und leistungsstarker Modelle wie den \u003Cstrong>Diffusion Transformers (DiT)\u003C/strong> führt.\u003C/li>\n\u003C/ol>\n\u003Cp>Um LLMs auf Consumer-Hardware auszuführen, werden oft quantisierte Dateiformate wie \u003Cstrong>GGUF\u003C/strong> verwendet, die ihre Größe und ihren Speicherverbrauch drastisch reduzieren.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Paper, das die Transformer-Architektur eingeführt hat: Attention Is All You Need","https://arxiv.org/abs/1706.03762",{"text":16,"url":17},"Erklärung von LLMs durch NVIDIA","https://www.nvidia.com/it-it/glossary/large-language-models/",{"text":19,"url":20},"Was ist ein LLM? - IBM","https://www.ibm.com/it-it/topics/large-language-models",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"LLM: Große Sprachmodelle. Ein LLM (Large Language Model), oder Großes Sprachmodell, ist eine Art von neuronalem Netzwerk, das auf riesigen Mengen von Textdaten (Bücher, Artikel, Code, Konversationen) trainiert wurde, mit dem Ziel, menschliche Sprache kohärent und kontextuell relevant zu verstehen und zu generieren. [2, 3] Berühmte Beispiele für LLMs sind die GPT-Serie von OpenAI (die Grundlage von ChatGPT), Llama von Meta, Gemini von Google und Claude von Anthropic. Wie funktionieren sie konzeptionell?; Im Kern ist ein LLM eine leistungsstarke Engine zur Vorhersage des nächsten Wortes. Wenn ihm ein Eingabetext (ein \"Prompt\") gegeben wird, berechnet das Modell die Wahrscheinlichkeit, welches Wort (oder \"Token\") als nächstes kommen sollte, basierend auf den sprachlichen Mustern, die es während des Trainings gelernt hat. Durch die tausendfache Wiederholung dieses Prozesses ist es in der Lage, Sätze, Absätze und ganze Dokumente zu generieren. Die Schlüsselarchitektur: der Transformer; Die LLM-Revolution wurde durch die Erfindung der Transformer-Architektur im Jahr 2017 ermöglicht. Ihre grundlegende Komponente, der Attention-Mechanismus, ermöglicht es dem Modell, die Bedeutung verschiedener Wörter im Eingabetext zu gewichten und so Beziehungen und Kontext auch über große Entfernungen hinweg zu verstehen. Das ist es, was LLMs ihre außergewöhnliche Fähigkeit verleiht, Konversationen zu folgen, Sprachen zu übersetzen und Code zu schreiben. LLMs und Bilderzeugung; Obwohl sie auf Text spezialisiert sind, sind LLMs auf zwei Arten eng mit der Welt der Bilderzeugung verbunden: 1. Der Text-Encoder (CLIP): Die Komponente, die unsere Prompts in Diffusionsmodellen interpretiert, ist im Grunde genommen eine Art von Sprachmodell, das auf der Transformer-Architektur basiert. 2. Hybrid-Architekturen (DiT): Innovationen im Bereich der LLMs, insbesondere die Transformer-Architektur, werden auch für die Bilderzeugung übernommen, was zur Entstehung neuer und leistungsstarker Modelle wie den Diffusion Transformers (DiT) führt. Um LLMs auf Consumer-Hardware auszuführen, werden oft quantisierte Dateiformate wie GGUF verwendet, die ihre Größe und ihren Speicherverbrauch drastisch reduzieren."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
