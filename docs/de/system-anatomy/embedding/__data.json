{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"de","system-anatomy","System Anatomy","teal","embedding","Embedding (Textuelle Inversion): Neue Konzepte lehren","\u003Cp>Ein \u003Cstrong>Embedding\u003C/strong>, auch bekannt als \u003Cstrong>Textuelle Inversion\u003C/strong>, ist eine kleine Datei, die dem Modell ein \u003Cstrong>neues visuelles Konzept\u003C/strong> beibringt, indem si...\u003C/p>\n","Ein Embedding, auch bekannt als Textuelle Inversion, ist eine kleine Datei, die dem Modell ein neues visuelles Konzept beibringt, indem si...","\u003Cp>Ein \u003Cstrong>Embedding\u003C/strong>, auch bekannt als \u003Cstrong>Textuelle Inversion\u003C/strong>, ist eine kleine Datei, die dem Modell ein \u003Cstrong>neues visuelles Konzept\u003C/strong> beibringt, indem sie es mit einem bestimmten Schlüsselwort verknüpft. [1]\u003C/p>\n\u003Cp>Stellen Sie sich das CLIP-Modell als ein riesiges Wörterbuch vor, das Wörter mit visuellen Ideen verknüpft. Ein Embedding ist, als ob Sie \u003Cstrong>diesem Wörterbuch ein neues Wort hinzufügen\u003C/strong> könnten. [2] Sie können beispielsweise ein Embedding mit 5-10 Fotos Ihrer Katze trainieren und es mit dem Schlüsselwort \u003Ccode>ohwx-cat\u003C/code> verknüpfen. Von diesem Moment an weiß das Modell jedes Mal, wenn Sie \u003Ccode>ohwx-cat\u003C/code> in Ihren Prompt schreiben, genau, auf welche Katze Sie sich beziehen.\u003C/p>\n\u003Ch3>Wie funktioniert es?\u003C/h3>\n\u003Cp>Im Gegensatz zu einer LoRa, die die Gewichte des UNet (des &quot;Malers&quot;) modifiziert, modifiziert ein Embedding nur die Gewichte des Text-Encoders (des &quot;Übersetzers&quot;). [3] Es lehrt das Modell nicht, in einem neuen Stil zu zeichnen, sondern es lehrt ihm die Bedeutung eines neuen &quot;Wortes&quot; (Tokens). [1] Die Datei eines Embeddings ist extrem klein, oft nur wenige Kilobyte.\u003C/p>\n\u003Ch3>Embedding vs. LoRa\u003C/h3>\n\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">Merkmal\u003C/th>\n\u003Cth align=\"left\">Embedding (Textuelle Inversion)\u003C/th>\n\u003Cth align=\"left\">LoRa\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Zweck\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Ein neues \u003Cstrong>Konzept\u003C/strong> lehren (Objekt, Charakter)\u003C/td>\n\u003Ctd align=\"left\">Einen neuen \u003Cstrong>Stil\u003C/strong> oder einen komplexen Charakter lehren\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Modifizierte Komponente\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Text-Encoder (CLIP)\u003C/td>\n\u003Ctd align=\"left\">UNet (und manchmal der Text-Encoder)\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Dateigröße\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Sehr klein (KB)\u003C/td>\n\u003Ctd align=\"left\">Klein (MB)\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003Cstrong>Flexibilität\u003C/strong>\u003C/td>\n\u003Ctd align=\"left\">Weniger flexibel, &quot;injiziert&quot; ein Konzept\u003C/td>\n\u003Ctd align=\"left\">Flexibler, kann den gesamten Stil ändern\u003C/td>\n\u003C/tr>\n\u003C/tbody>\u003C/table>\n\u003Ch3>Gängige Arten von Embeddings\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Stil:\u003C/strong> Obwohl für diesen Zweck weniger verbreitet als LoRas, können einige Embeddings einfache künstlerische Stile replizieren.\u003C/li>\n\u003Cli>\u003Cstrong>Charakter/Objekt:\u003C/strong> Die häufigste Verwendung. Perfekt, um konsistente Bilder einer bestimmten Person, eines Tieres oder eines Objekts zu erstellen.\u003C/li>\n\u003Cli>\u003Cstrong>Negatives Embedding:\u003C/strong> Eine besondere Art von Embedding, das mit Bildern von geringer Qualität trainiert wurde (z. B. mit deformierten Händen, hässlich usw.). Durch Einfügen des Schlüsselworts dieses Embeddings in den \u003Cem>negativen Prompt\u003C/em> wird die Gesamtqualität des Bildes erheblich verbessert. Berühmte Beispiele sind \u003Ccode>EasyNegative\u003C/code> oder \u003Ccode>bad-hands\u003C/code>. [2]\u003C/li>\n\u003C/ul>\n\u003Cp>In ComfyUI werden Embeddings normalerweise in einen bestimmten Ordner geladen und dann einfach durch Eingabe ihres Schlüsselworts (des Dateinamens) direkt im Prompt aufgerufen.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Original-Paper: Ein Bild ist ein Wort wert (Textuelle Inversion)","https://arxiv.org/abs/2208.01618",{"text":16,"url":17},"Erklärung von Embeddings auf Stable Diffusion Art","https://stablediffusionart.com/embedding/",{"text":19,"url":20},"Leitfaden zu Embeddings (TI) auf Civitai","https://civitai.com/articles/8/a-guide-to-the-different-ai-model-types",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"Embedding (Textuelle Inversion): Neue Konzepte lehren. Ein Embedding, auch bekannt als Textuelle Inversion, ist eine kleine Datei, die dem Modell ein neues visuelles Konzept beibringt, indem sie es mit einem bestimmten Schlüsselwort verknüpft. Stellen Sie sich das CLIP-Modell als ein riesiges Wörterbuch vor, das Wörter mit visuellen Ideen verknüpft. Ein Embedding ist, als ob Sie diesem Wörterbuch ein neues Wort hinzufügen könnten. Sie können beispielsweise ein Embedding mit 5-10 Fotos Ihrer Katze trainieren und es mit dem Schlüsselwort `ohwx-cat` verknüpfen. Von diesem Moment an weiß das Modell jedes Mal, wenn Sie `ohwx-cat` in Ihren Prompt schreiben, genau, auf welche Katze Sie sich beziehen. Wie funktioniert es?; Im Gegensatz zu einer LoRa, die die Gewichte des UNet (des \"Malers\") modifiziert, modifiziert ein Embedding nur die Gewichte des Text-Encoders (des \"Übersetzers\"). Es lehrt das Modell nicht, in einem neuen Stil zu zeichnen, sondern es lehrt ihm die Bedeutung eines neuen \"Wortes\" (Tokens). Die Datei eines Embeddings ist extrem klein, oft nur wenige Kilobyte. Embedding vs. LoRa; | Merkmal | Embedding (Textuelle Inversion) | LoRa | | : | :--- | | Zweck | Ein neues Konzept lehren (Objekt, Charakter) | Einen neuen Stil oder einen komplexen Charakter lehren | | Modifizierte Komponente | Text-Encoder (CLIP) | UNet (und manchmal der Text-Encoder) | | Dateigröße | Sehr klein (KB) | Klein (MB) | | Flexibilität | Weniger flexibel, \"injiziert\" ein Konzept | Flexibler, kann den gesamten Stil ändern | Gängige Arten von Embeddings; - Stil: Obwohl für diesen Zweck weniger verbreitet als LoRas, können einige Embeddings einfache künstlerische Stile replizieren. - Charakter/Objekt: Die häufigste Verwendung. Perfekt, um konsistente Bilder einer bestimmten Person, eines Tieres oder eines Objekts zu erstellen. - Negatives Embedding: Eine besondere Art von Embedding, das mit Bildern von geringer Qualität trainiert wurde (z. B. mit deformierten Händen, hässlich usw.). Durch Einfügen des Schlüsselworts dieses Embeddings in den negativen Prompt wird die Gesamtqualität des Bildes erheblich verbessert. Berühmte Beispiele sind `EasyNegative` oder `bad-hands`. In ComfyUI werden Embeddings normalerweise in einen bestimmten Ordner geladen und dann einfach durch Eingabe ihres Schlüsselworts (des Dateinamens) direkt im Prompt aufgerufen."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
