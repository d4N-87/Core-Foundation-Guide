{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"lang":1,"posts":2,"postIndex":150},"de",[3,11,16,21,26,31,36,44,49,54,59,64,69,74,82,87,92,100,105,110,115,120,125,130,135,140,145],{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":7,"title":8,"excerpt":9,"plainExcerpt":10},"advanced-topics","Advanced Topics","cyan","attention","Attention: Der Fokusmechanismus","\u003Cp>\u003Cstrong>Attention\u003C/strong> (oder \u003Cem>Self-Attention\u003C/em>) ist der Rechenmechanismus im Herzen der \u003Cstrong>Transformer\u003C/strong>-Architektur, der sowohl Sprachmodelle (LLMs) als auch in...\u003C/p>\n","Attention (oder Self-Attention) ist der Rechenmechanismus im Herzen der Transformer-Architektur, der sowohl Sprachmodelle (LLMs) als auch in...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":12,"title":13,"excerpt":14,"plainExcerpt":15},"dit","DiT: Die Diffusion Transformers","\u003Cp>Ein \u003Cstrong>DiT (Diffusion Transformer)\u003C/strong> ist eine neue Architektur für Diffusionsmodelle, die \u003Cstrong>das traditionelle UNet durch einen Transformer ersetzt\u003C/strong>. [...\u003C/p>\n","Ein DiT (Diffusion Transformer) ist eine neue Architektur für Diffusionsmodelle, die das traditionelle UNet durch einen Transformer ersetzt. [...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":17,"title":18,"excerpt":19,"plainExcerpt":20},"gguf","GGUF: Quantisierung für CPU und GPU","\u003Cp>\u003Cstrong>GGUF (Georgi Gerganov Universal Format)\u003C/strong> ist ein Dateiformat, das entwickelt wurde, um \u003Cstrong>quantisierte\u003C/strong> neuronale Modelle zu enthalten, d.h. in For...\u003C/p>\n","GGUF (Georgi Gerganov Universal Format) ist ein Dateiformat, das entwickelt wurde, um quantisierte neuronale Modelle zu enthalten, d.h. in For...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":22,"title":23,"excerpt":24,"plainExcerpt":25},"llm","LLM: Große Sprachmodelle","\u003Cp>Ein \u003Cstrong>LLM (Large Language Model)\u003C/strong>, oder Großes Sprachmodell, ist eine Art von neuronalem Netzwerk, das auf riesigen Mengen von Textdaten (Bücher, Art...\u003C/p>\n","Ein LLM (Large Language Model), oder Großes Sprachmodell, ist eine Art von neuronalem Netzwerk, das auf riesigen Mengen von Textdaten (Bücher, Art...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":27,"title":28,"excerpt":29,"plainExcerpt":30},"precision","Präzision: FP32, FP16, FP8, FP4 und die Rolle der GPU","\u003Cp>Die \u003Cstrong>Präzision\u003C/strong> eines Modells bezieht sich auf das numerische Format, das zum Speichern seiner &quot;Gewichte&quot; verwendet wird. Diese Gewichte sind reelle...\u003C/p>\n","Die Präzision eines Modells bezieht sich auf das numerische Format, das zum Speichern seiner \"Gewichte\" verwendet wird. Diese Gewichte sind reelle...",{"lang":1,"categorySlug":4,"categoryName":5,"categoryColor":6,"slug":32,"title":33,"excerpt":34,"plainExcerpt":35},"tokens","Token: Die Bausteine der Sprache","\u003Cp>\u003Cstrong>Token\u003C/strong> sind die grundlegenden Einheiten, in die ein Text zerlegt wird, bevor er von einem Sprachmodell wie CLIP verarbeitet wird. [1] Sie sind die ...\u003C/p>\n","Token sind die grundlegenden Einheiten, in die ein Text zerlegt wird, bevor er von einem Sprachmodell wie CLIP verarbeitet wird. [1] Sie sind die ...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":40,"title":41,"excerpt":42,"plainExcerpt":43},"core-concepts","Core Concepts","amber","cfg","CFG: Die Führungsskala","\u003Cp>Die \u003Cstrong>CFG (Classifier-Free Guidance) Skala\u003C/strong> ist einer der mächtigsten Parameter, die Ihnen zur Verfügung stehen. Einfach ausgedrückt, ist es ein Regl...\u003C/p>\n","Die CFG (Classifier-Free Guidance) Skala ist einer der mächtigsten Parameter, die Ihnen zur Verfügung stehen. Einfach ausgedrückt, ist es ein Regl...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":45,"title":46,"excerpt":47,"plainExcerpt":48},"denoise","Denoise: Die Stärke der Transformation","\u003Cp>Der Parameter \u003Cstrong>Denoise\u003C/strong> (oder \u003Cem>Denoising-Stärke\u003C/em>) ist ein Regler, der steuert, \u003Cstrong>wie viel des Ausgangsbildes\u003C/strong> während des Generierungsprozesses **t...\u003C/p>\n","Der Parameter Denoise (oder Denoising-Stärke) ist ein Regler, der steuert, wie viel des Ausgangsbildes während des Generierungsprozesses t...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":50,"title":51,"excerpt":52,"plainExcerpt":53},"prompt","Prompt: Dialog mit der KI","\u003Cp>Der \u003Cstrong>Prompt\u003C/strong> ist die textliche Anweisung, die Sie dem Modell geben, um das Bild zu beschreiben, das Sie erstellen möchten. Es ist der direkteste Weg...\u003C/p>\n","Der Prompt ist die textliche Anweisung, die Sie dem Modell geben, um das Bild zu beschreiben, das Sie erstellen möchten. Es ist der direkteste Weg...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":55,"title":56,"excerpt":57,"plainExcerpt":58},"sampler","Sampler: Die Denoising-Technik","\u003Cp>Der \u003Cstrong>Sampler\u003C/strong> (oder Abtastmethode) ist der Algorithmus, der den &quot;Denoising&quot;-Prozess (Rauschunterdrückung) bei jedem Schritt materiell ausführt. [1] ...\u003C/p>\n","Der Sampler (oder Abtastmethode) ist der Algorithmus, der den \"Denoising\"-Prozess (Rauschunterdrückung) bei jedem Schritt materiell ausführt. [1] ...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":60,"title":61,"excerpt":62,"plainExcerpt":63},"scheduler","Scheduler: Der Denoising-Plan","\u003Cp>Der \u003Cstrong>Scheduler\u003C/strong> (Planer) ist der Algorithmus, der die \u003Cstrong>Strategie\u003C/strong> und das \u003Cstrong>Tempo\u003C/strong> des Denoising-Prozesses definiert. [1] Wenn der Sampler die *T...\u003C/p>\n","Der Scheduler (Planer) ist der Algorithmus, der die Strategie und das Tempo des Denoising-Prozesses definiert. [1] Wenn der Sampler die *T...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":65,"title":66,"excerpt":67,"plainExcerpt":68},"seed","Seed: Die Kontrolle des Zufalls","\u003Cp>Der \u003Cstrong>Seed\u003C/strong> (auf Deutsch &quot;Samen&quot;) ist eine Zahl, die den Zufallszustand für die Generierung eines Bildes initialisiert. Stellen Sie ihn sich als den ...\u003C/p>\n","Der Seed (auf Deutsch \"Samen\") ist eine Zahl, die den Zufallszustand für die Generierung eines Bildes initialisiert. Stellen Sie ihn sich als den ...",{"lang":1,"categorySlug":37,"categoryName":38,"categoryColor":39,"slug":70,"title":71,"excerpt":72,"plainExcerpt":73},"steps","Schritte: Die Abtastschritte","\u003Cp>\u003Cstrong>Schritte\u003C/strong> (oder Abtastschritte) geben an, wie oft das Modell das Bild aus reinem Rauschen &quot;verfeinert&quot;. Es ist einer der wichtigsten Parameter, um ...\u003C/p>\n","Schritte (oder Abtastschritte) geben an, wie oft das Modell das Bild aus reinem Rauschen \"verfeinert\". Es ist einer der wichtigsten Parameter, um ...",{"lang":1,"categorySlug":75,"categoryName":76,"categoryColor":77,"slug":78,"title":79,"excerpt":80,"plainExcerpt":81},"fundamentals","Fundamentals","sky","deep_learning","Deep Learning: Das tiefe Lernen","\u003Cp>\u003Cstrong>Deep Learning\u003C/strong> (Tiefes Lernen) ist ein Teilbereich des Maschinellen Lernens, der auf \u003Cstrong>Tiefen Künstlichen Neuronalen Netzen\u003C/strong> basiert, d.h. auf neu...\u003C/p>\n","Deep Learning (Tiefes Lernen) ist ein Teilbereich des Maschinellen Lernens, der auf Tiefen Künstlichen Neuronalen Netzen basiert, d.h. auf neu...",{"lang":1,"categorySlug":75,"categoryName":76,"categoryColor":77,"slug":83,"title":84,"excerpt":85,"plainExcerpt":86},"inference","Inferenz: Verwendung des trainierten Modells","\u003Cp>\u003Cstrong>Inferenz\u003C/strong> ist der Prozess der \u003Cstrong>Verwendung eines bereits trainierten neuronalen Netzes\u003C/strong>, um Vorhersagen über neue und nie zuvor gesehene Daten zu ...\u003C/p>\n","Inferenz ist der Prozess der Verwendung eines bereits trainierten neuronalen Netzes, um Vorhersagen über neue und nie zuvor gesehene Daten zu ...",{"lang":1,"categorySlug":75,"categoryName":76,"categoryColor":77,"slug":88,"title":89,"excerpt":90,"plainExcerpt":91},"neural_network","Neuronales Netz: Das künstliche Gehirn","\u003Cp>Ein \u003Cstrong>Künstliches Neuronales Netz\u003C/strong> ist ein Rechenmodell, das von der Struktur und Funktionsweise des menschlichen Gehirns inspiriert ist. [1] Es ist ...\u003C/p>\n","Ein Künstliches Neuronales Netz ist ein Rechenmodell, das von der Struktur und Funktionsweise des menschlichen Gehirns inspiriert ist. [1] Es ist ...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":96,"title":97,"excerpt":98,"plainExcerpt":99},"system-anatomy","System Anatomy","teal","checkpoint","Checkpoint: Das Gehirn des Modells","\u003Cp>Der Begriff \u003Cstrong>Checkpoint\u003C/strong> (oder \u003Cem>Modell\u003C/em>) bezieht sich auf die Dateien, die die &quot;Gewichte&quot; des neuronalen Netzes enthalten, d.h. das **trainierte Geh...\u003C/p>\n","Der Begriff Checkpoint (oder Modell) bezieht sich auf die Dateien, die die \"Gewichte\" des neuronalen Netzes enthalten, d.h. das trainierte Geh...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":101,"title":102,"excerpt":103,"plainExcerpt":104},"clip","CLIP Text Encoder: Der Prompt-Übersetzer","\u003Cp>\u003Cstrong>CLIP (Contrastive Language-Image Pre-training)\u003C/strong> ist ein von OpenAI entwickeltes neuronales Modell, das die Art und Weise, wie KIs die Beziehung zwi...\u003C/p>\n","CLIP (Contrastive Language-Image Pre-training) ist ein von OpenAI entwickeltes neuronales Modell, das die Art und Weise, wie KIs die Beziehung zwi...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":106,"title":107,"excerpt":108,"plainExcerpt":109},"conditioning","Conditioning: Die Anweisungen für das UNet","\u003Cp>\u003Cstrong>Conditioning\u003C/strong> (Konditionierung) ist der Fachbegriff, der die \u003Cstrong>Leitdaten\u003C/strong> beschreibt, die dem UNet zur Verfügung gestellt werden, um den Bilderzeu...\u003C/p>\n","Conditioning (Konditionierung) ist der Fachbegriff, der die Leitdaten beschreibt, die dem UNet zur Verfügung gestellt werden, um den Bilderzeu...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":111,"title":112,"excerpt":113,"plainExcerpt":114},"controlnet","ControlNet: Die KI mit Bildern leiten","\u003Cp>\u003Cstrong>ControlNet\u003C/strong> ist eine neuronale Netzwerkarchitektur, die es ermöglicht, \u003Cstrong>Diffusionsmodelle mithilfe einer visuellen Eingabe\u003C/strong>, wie einem Bild oder ...\u003C/p>\n","ControlNet ist eine neuronale Netzwerkarchitektur, die es ermöglicht, Diffusionsmodelle mithilfe einer visuellen Eingabe, wie einem Bild oder ...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":116,"title":117,"excerpt":118,"plainExcerpt":119},"embedding","Embedding (Textuelle Inversion): Neue Konzepte lehren","\u003Cp>Ein \u003Cstrong>Embedding\u003C/strong>, auch bekannt als \u003Cstrong>Textuelle Inversion\u003C/strong>, ist eine kleine Datei, die dem Modell ein \u003Cstrong>neues visuelles Konzept\u003C/strong> beibringt, indem si...\u003C/p>\n","Ein Embedding, auch bekannt als Textuelle Inversion, ist eine kleine Datei, die dem Modell ein neues visuelles Konzept beibringt, indem si...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":121,"title":122,"excerpt":123,"plainExcerpt":124},"inpaint","Inpainting & Outpainting: Bilder modifizieren und erweitern","\u003Cp>\u003Cstrong>Inpainting\u003C/strong> und \u003Cstrong>Outpainting\u003C/strong> sind zwei leistungsstarke Techniken, die Diffusionsmodelle nicht verwenden, um ein Bild von Grund auf neu zu erstel...\u003C/p>\n","Inpainting und Outpainting sind zwei leistungsstarke Techniken, die Diffusionsmodelle nicht verwenden, um ein Bild von Grund auf neu zu erstel...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":126,"title":127,"excerpt":128,"plainExcerpt":129},"latent","Latenter Raum: Die komprimierte Welt der Bilder","\u003Cp>Der \u003Cstrong>Latente Raum\u003C/strong> ist eine komprimierte und niedrig aufgelöste Darstellung eines Bildes. Es ist eine &quot;Zwischenwelt&quot;, in der Diffusionsmodelle wie S...\u003C/p>\n","Der Latente Raum ist eine komprimierte und niedrig aufgelöste Darstellung eines Bildes. Es ist eine \"Zwischenwelt\", in der Diffusionsmodelle wie S...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":131,"title":132,"excerpt":133,"plainExcerpt":134},"lora","LoRa: Leichte Stilmodifikatoren","\u003Cp>Eine \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> ist eine kleine Datei, die gezielte Änderungen an einem vollständigen Checkpoint-Modell vornimmt, ohne es dauerhaf...\u003C/p>\n","Eine LoRa (Low-Rank Adaptation) ist eine kleine Datei, die gezielte Änderungen an einem vollständigen Checkpoint-Modell vornimmt, ohne es dauerhaf...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":136,"title":137,"excerpt":138,"plainExcerpt":139},"segmentation","Segmentierung: Die Szene verstehen","\u003Cp>Die \u003Cstrong>Bildsegmentierung\u003C/strong> ist ein Prozess der Computer Vision, der darin besteht, \u003Cstrong>ein Bild in mehrere Segmente oder Regionen zu unterteilen\u003C/strong>, wobei...\u003C/p>\n","Die Bildsegmentierung ist ein Prozess der Computer Vision, der darin besteht, ein Bild in mehrere Segmente oder Regionen zu unterteilen, wobei...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":141,"title":142,"excerpt":143,"plainExcerpt":144},"unet","UNet: Das Herz des Denoising","\u003Cp>Das \u003Cstrong>UNet\u003C/strong> ist die zentrale und wichtigste Komponente eines Diffusionsmodells wie Stable Diffusion. Es ist das neuronale Netz, das lernt, **Rauschen...\u003C/p>\n","Das UNet ist die zentrale und wichtigste Komponente eines Diffusionsmodells wie Stable Diffusion. Es ist das neuronale Netz, das lernt, Rauschen...",{"lang":1,"categorySlug":93,"categoryName":94,"categoryColor":95,"slug":146,"title":147,"excerpt":148,"plainExcerpt":149},"vae","VAE: Der visuelle Decoder","\u003Cp>Der \u003Cstrong>VAE (Variational Autoencoder)\u003C/strong> ist der endgültige Decoder Ihres Systems. [1, 2]\u003C/p>\n\u003Cp>Stellen Sie sich vor, das KI-Modell &quot;denkt&quot; nicht in Bildern, ...\u003C/p>\n","Der VAE (Variational Autoencoder) ist der endgültige Decoder Ihres Systems. [1, 2]\n\nStellen Sie sich vor, das KI-Modell \"denkt\" nicht in Bildern, ...",[151,156,169,178],{"categoryName":76,"categorySlug":75,"posts":152},[153,154,155],{"title":79,"slug":78},{"title":84,"slug":83},{"title":89,"slug":88},{"categoryName":94,"categorySlug":93,"posts":157},[158,159,160,161,162,163,164,165,166,167,168],{"title":97,"slug":96},{"title":102,"slug":101},{"title":107,"slug":106},{"title":112,"slug":111},{"title":117,"slug":116},{"title":122,"slug":121},{"title":127,"slug":126},{"title":132,"slug":131},{"title":137,"slug":136},{"title":142,"slug":141},{"title":147,"slug":146},{"categoryName":38,"categorySlug":37,"posts":170},[171,172,173,174,175,176,177],{"title":41,"slug":40},{"title":46,"slug":45},{"title":51,"slug":50},{"title":56,"slug":55},{"title":61,"slug":60},{"title":66,"slug":65},{"title":71,"slug":70},{"categoryName":5,"categorySlug":4,"posts":179},[180,181,182,183,184,185],{"title":8,"slug":7},{"title":13,"slug":12},{"title":18,"slug":17},{"title":23,"slug":22},{"title":28,"slug":27},{"title":33,"slug":32}],"uses":{"params":["lang"]}}]}
