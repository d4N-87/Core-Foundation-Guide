{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":24,"seo":110,"textContent":111},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"it","system-anatomy","System Anatomy","teal","checkpoint","Checkpoint: Il Cervello del Modello","\u003Cp>Il termine \u003Cstrong>Checkpoint\u003C/strong> (o \u003Cem>Modello\u003C/em>) si riferisce ai file che contengono i &quot;pesi&quot; della rete neurale, ovvero il \u003Cstrong>cervello addestrato\u003C/strong> dell&#39;intell...\u003C/p>\n","Il termine Checkpoint (o Modello) si riferisce ai file che contengono i \"pesi\" della rete neurale, ovvero il cervello addestrato dell'intell...","\u003Cp>Il termine \u003Cstrong>Checkpoint\u003C/strong> (o \u003Cem>Modello\u003C/em>) si riferisce ai file che contengono i &quot;pesi&quot; della rete neurale, ovvero il \u003Cstrong>cervello addestrato\u003C/strong> dell&#39;intelligenza artificiale. [1] Caricare un checkpoint è il primo passo di ogni workflow, ma il modo in cui viene fatto riflette due approcci principali: monolitico e modulare.\u003C/p>\n\u003Ch3>1. L&#39;Approccio Monolitico (Tradizionale)\u003C/h3>\n\u003Cp>In questo approccio, un singolo file di checkpoint (con estensione \u003Ccode>.ckpt\u003C/code> o \u003Ccode>.safetensors\u003C/code>) contiene tutti e tre i componenti chiave necessari per la generazione: [3]\u003C/p>\n\u003Cul>\n\u003Cli>La \u003Cstrong>UNet\u003C/strong>, il cuore del modello di diffusione.\u003C/li>\n\u003Cli>Il \u003Cstrong>Text Encoder\u003C/strong> (CLIP), per interpretare il prompt.\u003C/li>\n\u003Cli>Il \u003Cstrong>VAE\u003C/strong>, per creare l&#39;immagine finale.\u003C/li>\n\u003C/ul>\n\u003Cp>Questo metodo è semplice e diretto: carichi un file e hai tutto ciò che ti serve. È molto comune per i modelli basati su Stable Diffusion 1.5.\u003C/p>\n\u003Ch3>2. L&#39;Approccio Modulare (Moderno)\u003C/h3>\n\u003Cp>Con l&#39;avvento di modelli più complessi come FLUX.1 e la flessibilità di interfacce come ComfyUI, è diventato comune caricare i componenti separatamente. In questo scenario, non carichi un singolo &quot;checkpoint&quot;, ma i suoi pezzi costitutivi:\u003C/p>\n\u003Cul>\n\u003Cli>Un file per la \u003Cstrong>UNet\u003C/strong> (spesso chiamato &quot;modello base&quot; o &quot;diffusion model&quot;).\u003C/li>\n\u003Cli>Uno o più file per il \u003Cstrong>CLIP Text Encoder\u003C/strong> (FLUX.1 ne usa addirittura due).\u003C/li>\n\u003Cli>Un file per il \u003Cstrong>VAE\u003C/strong>.\u003C/li>\n\u003C/ul>\n\u003Cp>Questo approccio offre una flessibilità enorme: puoi, ad esempio, usare la UNet di un modello con il VAE di un altro per correggere problemi di colori, o sperimentare con diversi Text Encoder. [1]\u003C/p>\n\u003Cp>\u003Cstrong>Quindi, ha ancora senso parlare di Checkpoint?\u003C/strong>\nSì. Il termine &quot;checkpoint&quot; è ancora usato comunemente nella community per riferirsi al file principale del modello, specialmente la \u003Cstrong>UNet\u003C/strong>. Quando scarichi un modello &quot;finetuned&quot; da Civitai, stai scaricando principalmente una UNet modificata, che potrai usare sia in modo monolitico (se contiene tutto) sia in modo modulare, abbinandola a CLIP e VAE a tua scelta.\u003C/p>\n\u003Ch3>La Gerarchia dei Modelli\u003C/h3>\n\u003Cp>Possiamo classificare i modelli in una sorta di gerarchia:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Modelli Base (Base Models):\u003C/strong>\nSono le fondamenta. Rilasciati da laboratori di ricerca (es. Stability AI, Black Forest Labs), sono addestrati su dataset enormi e generici. Sono potentissimi ma spesso non hanno uno stile artistico definito. Esempi: \u003Ccode>Stable Diffusion 1.5\u003C/code>, \u003Ccode>SDXL Base\u003C/code>. [3]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Modelli Finetuned (Finetuned Models):\u003C/strong>\nSono modelli base che la community ha ulteriormente addestrato su dataset più piccoli e specifici per ottenere uno stile particolare (es. fotorealismo, anime, fantasy). La stragrande maggioranza dei modelli su siti come Civitai rientra in questa categoria. [1, 3]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Modelli Custom (Merge):\u003C/strong>\nQuesti non sono addestrati, ma creati \u003Cstrong>mescolando i pesi\u003C/strong> di due o più modelli finetuned. È una tecnica molto popolare per combinare gli stili di diversi modelli e crearne uno nuovo e unico. È più un&#39;arte che una scienza, e i risultati possono variare. [3]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Modelli Distillati (Distilled Models):\u003C/strong>\nSono una categoria speciale. Un modello &quot;distillato&quot; è una versione più piccola e veloce di un modello base, creata con un processo di addestramento che &quot;distilla&quot; la conoscenza del modello più grande. L&#39;esempio più famoso è \u003Cstrong>SDXL Turbo\u003C/strong>, che può generare immagini di alta qualità in pochissimi steps (1-4), a scapito di una minore flessibilità. [4] O anche versioni come FLUX.1 Dev distillata dalla Pro.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3>Formati: \u003Ccode>.ckpt\u003C/code> vs. \u003Ccode>.safetensors\u003C/code>\u003C/h3>\n\u003Cp>Indipendentemente dall&#39;approccio, i file sono distribuiti in due formati:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>\u003Ccode>.ckpt\u003C/code> (Checkpoint):\u003C/strong> Il formato originale basato su &quot;pickle&quot; di Python. Potenzialmente insicuro, in quanto può contenere codice eseguibile. [2]\u003C/li>\n\u003Cli>\u003Cstrong>\u003Ccode>.safetensors\u003C/code> (Safe Tensors):\u003C/strong> Il nuovo standard, più sicuro e veloce da caricare, che contiene solo i dati del modello. [2] \u003Cstrong>È sempre raccomandabile preferire il formato \u003Ccode>.safetensors\u003C/code> quando disponibile.\u003C/strong>\u003C/li>\n\u003C/ul>\n",[12,15,18,21],{"text":13,"url":14},"Cosa sono i Modelli di Stable Diffusion? - Stable Diffusion Art","https://stablediffusionart.com/models/",{"text":16,"url":17},"Spiegazione dei formati .ckpt e .safetensors - Hugging Face","https://huggingface.co/docs/safetensors/index",{"text":19,"url":20},"Guida ai diversi tipi di modelli AI","https://civitai.com/articles/8/a-guide-to-the-different-ai-model-types",{"text":22,"url":23},"Introduzione ai Modelli Distillati (SDXL Turbo)","https://stability.ai/news/sdxl-turbo",{"it":25,"en":40,"fr":55,"es":69,"de":84,"pt":99},{"category":26,"connections":27,"backToHub":28,"noPostsFound":29,"pageTitleCategory":26,"initializing":30,"backToArticles":31,"sources":32,"searchPlaceholder":33,"showMap":34,"hideMap":35,"listenToArticle":36,"playing":37,"paused":38,"voice":39},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":41,"connections":42,"backToHub":43,"noPostsFound":44,"pageTitleCategory":41,"initializing":45,"backToArticles":46,"sources":47,"searchPlaceholder":48,"showMap":49,"hideMap":50,"listenToArticle":51,"playing":52,"paused":53,"voice":54},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":56,"connections":57,"backToHub":58,"noPostsFound":59,"pageTitleCategory":56,"initializing":60,"backToArticles":61,"sources":47,"searchPlaceholder":62,"showMap":63,"hideMap":64,"listenToArticle":65,"playing":66,"paused":67,"voice":68},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":70,"connections":71,"backToHub":72,"noPostsFound":73,"pageTitleCategory":70,"initializing":74,"backToArticles":75,"sources":76,"searchPlaceholder":77,"showMap":78,"hideMap":79,"listenToArticle":80,"playing":81,"paused":82,"voice":83},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":85,"connections":86,"backToHub":87,"noPostsFound":88,"pageTitleCategory":85,"initializing":89,"backToArticles":90,"sources":91,"searchPlaceholder":92,"showMap":93,"hideMap":94,"listenToArticle":95,"playing":96,"paused":97,"voice":98},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":26,"connections":100,"backToHub":101,"noPostsFound":102,"pageTitleCategory":26,"initializing":74,"backToArticles":103,"sources":104,"searchPlaceholder":105,"showMap":106,"hideMap":79,"listenToArticle":107,"playing":108,"paused":109,"voice":83},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"Checkpoint: Il Cervello del Modello. Il termine Checkpoint (o Modello) si riferisce ai file che contengono i \"pesi\" della rete neurale, ovvero il cervello addestrato dell'intelligenza artificiale. Caricare un checkpoint è il primo passo di ogni workflow, ma il modo in cui viene fatto riflette due approcci principali: monolitico e modulare. 1. L'Approccio Monolitico (Tradizionale); In questo approccio, un singolo file di checkpoint (con estensione `.ckpt` o `.safetensors`) contiene tutti e tre i componenti chiave necessari per la generazione: - La UNet, il cuore del modello di diffusione. - Il Text Encoder (CLIP), per interpretare il prompt. - Il VAE, per creare l'immagine finale. Questo metodo è semplice e diretto: carichi un file e hai tutto ciò che ti serve. È molto comune per i modelli basati su Stable Diffusion 1.5. 2. L'Approccio Modulare (Moderno); Con l'avvento di modelli più complessi come FLUX.1 e la flessibilità di interfacce come ComfyUI, è diventato comune caricare i componenti separatamente. In questo scenario, non carichi un singolo \"checkpoint\", ma i suoi pezzi costitutivi: - Un file per la UNet (spesso chiamato \"modello base\" o \"diffusion model\"). - Uno o più file per il CLIP Text Encoder (FLUX.1 ne usa addirittura due). - Un file per il VAE. Questo approccio offre una flessibilità enorme: puoi, ad esempio, usare la UNet di un modello con il VAE di un altro per correggere problemi di colori, o sperimentare con diversi Text Encoder. Quindi, ha ancora senso parlare di Checkpoint? Sì. Il termine \"checkpoint\" è ancora usato comunemente nella community per riferirsi al file principale del modello, specialmente la UNet. Quando scarichi un modello \"finetuned\" da Civitai, stai scaricando principalmente una UNet modificata, che potrai usare sia in modo monolitico (se contiene tutto) sia in modo modulare, abbinandola a CLIP e VAE a tua scelta. La Gerarchia dei Modelli; Possiamo classificare i modelli in una sorta di gerarchia: 1. Modelli Base (Base Models): Sono le fondamenta. Rilasciati da laboratori di ricerca (es. Stability AI, Black Forest Labs), sono addestrati su dataset enormi e generici. Sono potentissimi ma spesso non hanno uno stile artistico definito. Esempi: `Stable Diffusion 1.5`, `SDXL Base`. 2. Modelli Finetuned (Finetuned Models): Sono modelli base che la community ha ulteriormente addestrato su dataset più piccoli e specifici per ottenere uno stile particolare (es. fotorealismo, anime, fantasy). La stragrande maggioranza dei modelli su siti come Civitai rientra in questa categoria. [1, 3] 3. Modelli Custom (Merge): Questi non sono addestrati, ma creati mescolando i pesi di due o più modelli finetuned. È una tecnica molto popolare per combinare gli stili di diversi modelli e crearne uno nuovo e unico. È più un'arte che una scienza, e i risultati possono variare. 4. Modelli Distillati (Distilled Models): Sono una categoria speciale. Un modello \"distillato\" è una versione più piccola e veloce di un modello base, creata con un processo di addestramento che \"distilla\" la conoscenza del modello più grande. L'esempio più famoso è SDXL Turbo, che può generare immagini di alta qualità in pochissimi steps (1-4), a scapito di una minore flessibilità. O anche versioni come FLUX.1 Dev distillata dalla Pro. Formati: `.ckpt` vs. `.safetensors`; Indipendentemente dall'approccio, i file sono distribuiti in due formati: - `.ckpt` (Checkpoint): Il formato originale basato su \"pickle\" di Python. Potenzialmente insicuro, in quanto può contenere codice eseguibile. - `.safetensors` (Safe Tensors): Il nuovo standard, più sicuro e veloce da caricare, che contiene solo i dati del modello. È sempre raccomandabile preferire il formato `.safetensors` quando disponibile."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
