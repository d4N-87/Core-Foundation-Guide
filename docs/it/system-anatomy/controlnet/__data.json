{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"it","system-anatomy","System Anatomy","teal","controlnet","ControlNet: Guidare l'AI con le Immagini","\u003Cp>\u003Cstrong>ControlNet\u003C/strong> è una architettura di rete neurale che permette di \u003Cstrong>condizionare e controllare i modelli di diffusione usando un input visivo\u003C/strong>, come ...\u003C/p>\n","ControlNet è una architettura di rete neurale che permette di condizionare e controllare i modelli di diffusione usando un input visivo, come ...","\u003Cp>\u003Cstrong>ControlNet\u003C/strong> è una architettura di rete neurale che permette di \u003Cstrong>condizionare e controllare i modelli di diffusione usando un input visivo\u003C/strong>, come un&#39;immagine o una mappa di dati. [1] In parole semplici, è un sistema che si affianca al modello principale (la UNet) e gli fornisce una &quot;guida visiva&quot; extra, molto più precisa e diretta di un semplice prompt testuale. [2]\u003C/p>\n\u003Cp>Pensa al modello di diffusione come a un artista talentuoso ma a cui puoi dare solo istruzioni verbali. ControlNet è come dargli un \u003Cstrong>tracciato\u003C/strong> o uno \u003Cstrong>schizzo preparatorio\u003C/strong>: l&#39;artista manterrà la sua creatività e il suo stile, ma seguirà fedelmente la composizione, la posa o la struttura che gli hai fornito. [2]\u003C/p>\n\u003Ch3>Il Workflow di ControlNet\u003C/h3>\n\u003Cp>Un tipico workflow con ControlNet si svolge in due fasi principali:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Preprocessing (Pre-elaborazione):\u003C/strong>\nSi parte da un&#39;immagine di input. Questa immagine viene processata da un \u003Cstrong>preprocessore\u003C/strong>, un algoritmo che ne estrae una &quot;mappa&quot; di informazioni specifiche. Questa mappa è ciò che verrà usato come guida. Esistono molti tipi di preprocessori, ognuno specializzato in un tipo di controllo diverso. [3]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Applicazione del Modello ControlNet:\u003C/strong>\nLa mappa generata viene passata a un modello ControlNet specifico, addestrato per &quot;capire&quot; quel tipo di mappa. Questo modello ControlNet lavora in parallelo alla UNet del checkpoint principale, iniettando la sua guida visiva ad ogni step del processo di denoising per forzare il risultato a rispettare la mappa. [1]\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3>Esempi di Preprocessori e Modelli Comuni\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cp>\u003Cstrong>Canny:\u003C/strong>\n  È un algoritmo di \u003Cstrong>rilevamento dei bordi\u003C/strong> (edge detection). Il preprocessore \u003Ccode>Canny\u003C/code> prende un&#39;immagine e la trasforma in un disegno al tratto in bianco e nero, evidenziando solo i contorni degli oggetti. [3] È estremamente utile per replicare la composizione esatta di una foto o di un disegno.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Depth (Profondità):\u003C/strong>\n  Il preprocessore \u003Ccode>Depth\u003C/code> analizza un&#39;immagine e crea una \u003Cstrong>mappa di profondità\u003C/strong>, dove i colori (solitamente dal bianco al nero) indicano quali oggetti sono più vicini o più lontani dalla &quot;camera&quot;. [3] Questo permette di trasferire la disposizione 3D di una scena a un&#39;immagine completamente diversa.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>OpenPose:\u003C/strong>\n  Questo preprocessore rileva lo &quot;scheletro&quot; di una o più persone in un&#39;immagine, creando una mappa con la \u003Cstrong>posa esatta\u003C/strong> di ogni figura. È lo strumento definitivo per controllare la postura e la posizione dei personaggi.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Scribble / Sketch:\u003C/strong>\n  Permette di usare un semplice scarabocchio o un disegno fatto a mano come guida per la composizione generale dell&#39;immagine.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>ControlNet ha aperto la porta a un livello di controllo e coerenza prima impensabile, diventando uno strumento indispensabile per l&#39;animazione, il design e qualsiasi applicazione che richieda risultati precisi e riproducibili.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Paper Originale: Adding Conditional Control to Text-to-Image Diffusion Models","https://arxiv.org/abs/2302.05543",{"text":16,"url":17},"Guida illustrata a ControlNet","https://www.assemblyai.com/blog/controlnet-explained-a-new-way-to-control-stable-diffusion/",{"text":19,"url":20},"Repository GitHub Ufficiale con i modelli","https://github.com/lllyasviel/ControlNet",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"ControlNet: Guidare l'AI con le Immagini. ControlNet è una architettura di rete neurale che permette di condizionare e controllare i modelli di diffusione usando un input visivo, come un'immagine o una mappa di dati. In parole semplici, è un sistema che si affianca al modello principale (la UNet) e gli fornisce una \"guida visiva\" extra, molto più precisa e diretta di un semplice prompt testuale. Pensa al modello di diffusione come a un artista talentuoso ma a cui puoi dare solo istruzioni verbali. ControlNet è come dargli un tracciato o uno schizzo preparatorio: l'artista manterrà la sua creatività e il suo stile, ma seguirà fedelmente la composizione, la posa o la struttura che gli hai fornito. Il Workflow di ControlNet; Un tipico workflow con ControlNet si svolge in due fasi principali: 1. Preprocessing (Pre-elaborazione): Si parte da un'immagine di input. Questa immagine viene processata da un preprocessore, un algoritmo che ne estrae una \"mappa\" di informazioni specifiche. Questa mappa è ciò che verrà usato come guida. Esistono molti tipi di preprocessori, ognuno specializzato in un tipo di controllo diverso. 2. Applicazione del Modello ControlNet: La mappa generata viene passata a un modello ControlNet specifico, addestrato per \"capire\" quel tipo di mappa. Questo modello ControlNet lavora in parallelo alla UNet del checkpoint principale, iniettando la sua guida visiva ad ogni step del processo di denoising per forzare il risultato a rispettare la mappa. Esempi di Preprocessori e Modelli Comuni; - Canny: È un algoritmo di rilevamento dei bordi (edge detection). Il preprocessore `Canny` prende un'immagine e la trasforma in un disegno al tratto in bianco e nero, evidenziando solo i contorni degli oggetti. È estremamente utile per replicare la composizione esatta di una foto o di un disegno. - Depth (Profondità): Il preprocessore `Depth` analizza un'immagine e crea una mappa di profondità, dove i colori (solitamente dal bianco al nero) indicano quali oggetti sono più vicini o più lontani dalla \"camera\". Questo permette di trasferire la disposizione 3D di una scena a un'immagine completamente diversa. - OpenPose: Questo preprocessore rileva lo \"scheletro\" di una o più persone in un'immagine, creando una mappa con la posa esatta di ogni figura. È lo strumento definitivo per controllare la postura e la posizione dei personaggi. - Scribble / Sketch: Permette di usare un semplice scarabocchio o un disegno fatto a mano come guida per la composizione generale dell'immagine. ControlNet ha aperto la porta a un livello di controllo e coerenza prima impensabile, diventando uno strumento indispensabile per l'animazione, il design e qualsiasi applicazione che richieda risultati precisi e riproducibili."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
