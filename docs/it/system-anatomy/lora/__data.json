{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"it","system-anatomy","System Anatomy","teal","lora","LoRa: Modificatori Leggeri di Stile","\u003Cp>Una \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> è un piccolo file che applica modifiche mirate a un modello checkpoint completo, senza alterarlo permanentemente. [...\u003C/p>\n","Una LoRa (Low-Rank Adaptation) è un piccolo file che applica modifiche mirate a un modello checkpoint completo, senza alterarlo permanentemente. [...","\u003Cp>Una \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> è un piccolo file che applica modifiche mirate a un modello checkpoint completo, senza alterarlo permanentemente. [1] Pensa a una LoRa come a un \u003Cstrong>set di istruzioni aggiuntive\u003C/strong> o a un \u003Cstrong>filtro trasparente\u003C/strong> che metti sopra il &quot;cervello&quot; principale (il checkpoint) per fargli adottare uno stile specifico, replicare un personaggio o un concetto. [2]\u003C/p>\n\u003Cp>Il vantaggio principale delle LoRa è la loro \u003Cstrong>dimensione ridotta\u003C/strong>. Mentre un checkpoint completo può pesare diversi gigabyte, una LoRa pesa tipicamente solo pochi megabyte (da 2 a 200 MB). [3] Questo le rende facili da scaricare, condividere e utilizzare.\u003C/p>\n\u003Ch3>Come Funzionano?\u003C/h3>\n\u003Cp>Invece di riaddestrare l&#39;intero modello (un processo costoso), una LoRa viene addestrata per &quot;intercettare&quot; e modificare solo una piccola parte dei pesi della UNet e del Text Encoder. [3] Quando applichi una LoRa, i suoi piccoli pesi vengono aggiunti a quelli del modello principale durante la generazione, influenzando il risultato finale.\u003C/p>\n\u003Ch3>Tipi Comuni di LoRa\u003C/h3>\n\u003Cp>Le LoRa sono incredibilmente versatili e possono essere addestrate per diversi scopi:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Stile (Style LoRa):\u003C/strong>\nQueste LoRa insegnano al modello uno stile artistico specifico (es. &quot;stile Ghibli&quot;, &quot;pixel art&quot;, &quot;pittura a olio barocca&quot;). Sono tra le più popolari. [2]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Personaggio (Character LoRa):\u003C/strong>\nAddestrate su immagini di un personaggio specifico (reale o di finzione), permettono di inserire quel personaggio in qualsiasi scena con una buona coerenza.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Concetto (Concept LoRa):\u003C/strong>\nPossono insegnare al modello un concetto più astratto, come una particolare posa, un tipo di abbigliamento o un oggetto specifico.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3>Utilizzo in ComfyUI\u003C/h3>\n\u003Cp>In ComfyUI, le LoRa vengono caricate tramite un nodo \u003Ccode>Load LoRA\u003C/code> che si inserisce tipicamente tra il \u003Ccode>Load Checkpoint\u003C/code> e il \u003Ccode>KSampler\u003C/code>. Questo nodo prende in input il modello e il CLIP dal checkpoint e restituisce una versione &quot;modificata&quot; di entrambi, pronta per essere usata nel resto del workflow.\u003C/p>\n\u003Cp>È possibile anche \u003Cstrong>combinare più LoRa\u003C/strong> (un processo chiamato \u003Cem>stacking\u003C/em>), applicando diversi filtri in sequenza, anche se questo può portare a risultati imprevedibili se le LoRa sono in conflitto tra loro.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Paper Originale: LoRA: Low-Rank Adaptation of Large Language Models","https://arxiv.org/abs/2106.09685",{"text":16,"url":17},"Guida alle LoRa su Civitai","https://civitai.com/articles/8/a-guide-to-the-different-ai-model-types",{"text":19,"url":20},"Spiegazione tecnica delle LoRa su Hugging Face","https://huggingface.co/docs/diffusers/main/en/training/lora",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"LoRa: Modificatori Leggeri di Stile. Una LoRa (Low-Rank Adaptation) è un piccolo file che applica modifiche mirate a un modello checkpoint completo, senza alterarlo permanentemente. Pensa a una LoRa come a un set di istruzioni aggiuntive o a un filtro trasparente che metti sopra il \"cervello\" principale (il checkpoint) per fargli adottare uno stile specifico, replicare un personaggio o un concetto. Il vantaggio principale delle LoRa è la loro dimensione ridotta. Mentre un checkpoint completo può pesare diversi gigabyte, una LoRa pesa tipicamente solo pochi megabyte (da 2 a 200 MB). Questo le rende facili da scaricare, condividere e utilizzare. Come Funzionano?; Invece di riaddestrare l'intero modello (un processo costoso), una LoRa viene addestrata per \"intercettare\" e modificare solo una piccola parte dei pesi della UNet e del Text Encoder. Quando applichi una LoRa, i suoi piccoli pesi vengono aggiunti a quelli del modello principale durante la generazione, influenzando il risultato finale. Tipi Comuni di LoRa; Le LoRa sono incredibilmente versatili e possono essere addestrate per diversi scopi: 1. Stile (Style LoRa): Queste LoRa insegnano al modello uno stile artistico specifico (es. \"stile Ghibli\", \"pixel art\", \"pittura a olio barocca\"). Sono tra le più popolari. 2. Personaggio (Character LoRa): Addestrate su immagini di un personaggio specifico (reale o di finzione), permettono di inserire quel personaggio in qualsiasi scena con una buona coerenza. 3. Concetto (Concept LoRa): Possono insegnare al modello un concetto più astratto, come una particolare posa, un tipo di abbigliamento o un oggetto specifico. Utilizzo in ComfyUI; In ComfyUI, le LoRa vengono caricate tramite un nodo `Load LoRA` che si inserisce tipicamente tra il `Load Checkpoint` e il `KSampler`. Questo nodo prende in input il modello e il CLIP dal checkpoint e restituisce una versione \"modificata\" di entrambi, pronta per essere usata nel resto del workflow. È possibile anche combinare più LoRa (un processo chiamato stacking), applicando diversi filtri in sequenza, anche se questo può portare a risultati imprevedibili se le LoRa sono in conflitto tra loro."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
