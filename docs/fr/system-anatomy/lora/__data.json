{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"fr","system-anatomy","System Anatomy","teal","lora","LoRa : Modificateurs de Style Légers","\u003Cp>Une \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> est un petit fichier qui applique des modifications ciblées à un modèle de point de contrôle complet, sans l&#39;altére...\u003C/p>\n","Une LoRa (Low-Rank Adaptation) est un petit fichier qui applique des modifications ciblées à un modèle de point de contrôle complet, sans l'altére...","\u003Cp>Une \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> est un petit fichier qui applique des modifications ciblées à un modèle de point de contrôle complet, sans l&#39;altérer de façon permanente. [1] Pensez à une LoRa comme à un \u003Cstrong>ensemble d&#39;instructions supplémentaires\u003C/strong> ou à un \u003Cstrong>filtre transparent\u003C/strong> que vous placez sur le &quot;cerveau&quot; principal (le point de contrôle) pour lui faire adopter un style spécifique, reproduire un personnage ou un concept. [2]\u003C/p>\n\u003Cp>L&#39;avantage principal des LoRa est leur \u003Cstrong>taille réduite\u003C/strong>. Alors qu&#39;un point de contrôle complet peut peser plusieurs gigaoctets, une LoRa ne pèse généralement que quelques mégaoctets (de 2 à 200 Mo). [3] Cela les rend faciles à télécharger, à partager et à utiliser.\u003C/p>\n\u003Ch3>Comment fonctionnent-elles ?\u003C/h3>\n\u003Cp>Au lieu de ré-entraîner l&#39;ensemble du modèle (un processus coûteux), une LoRa est entraînée pour &quot;intercepter&quot; et modifier seulement une petite partie des poids de l&#39;UNet et de l&#39;Encodeur de Texte. [3] Lorsque vous appliquez une LoRa, ses petits poids sont ajoutés à ceux du modèle principal pendant la génération, influençant le résultat final.\u003C/p>\n\u003Ch3>Types courants de LoRa\u003C/h3>\n\u003Cp>Les LoRa sont incroyablement polyvalentes et peuvent être entraînées à des fins diverses :\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Style (LoRa de Style) :\u003C/strong>\nCes LoRa enseignent au modèle un style artistique spécifique (par exemple, &quot;style Ghibli&quot;, &quot;pixel art&quot;, &quot;peinture à l&#39;huile baroque&quot;). Elles sont parmi les plus populaires. [2]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Personnage (LoRa de Personnage) :\u003C/strong>\nEntraînées sur des images d&#39;un personnage spécifique (réel ou fictif), elles permettent d&#39;insérer ce personnage dans n&#39;importe quelle scène avec une bonne cohérence.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Concept (LoRa de Concept) :\u003C/strong>\nElles peuvent enseigner au modèle un concept plus abstrait, comme une pose particulière, un type de vêtement ou un objet spécifique.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3>Utilisation dans ComfyUI\u003C/h3>\n\u003Cp>Dans ComfyUI, les LoRa sont chargées via un nœud \u003Ccode>Load LoRA\u003C/code> qui s&#39;insère généralement entre le \u003Ccode>Load Checkpoint\u003C/code> et le \u003Ccode>KSampler\u003C/code>. Ce nœud prend en entrée le modèle et le CLIP du point de contrôle et renvoie une version &quot;modifiée&quot; des deux, prête à être utilisée dans le reste du flux de travail.\u003C/p>\n\u003Cp>Il est également possible de \u003Cstrong>combiner plusieurs LoRa\u003C/strong> (un processus appelé \u003Cem>empilement\u003C/em>), en appliquant différents filtres en séquence, bien que cela puisse conduire à des résultats imprévisibles si les LoRa entrent en conflit les unes avec les autres.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Article Original : LoRA : Adaptation de rang faible des grands modèles de langage","https://arxiv.org/abs/2106.09685",{"text":16,"url":17},"Guide des LoRa sur Civitai","https://civitai.com/articles/8/a-guide-to-the-different-ai-model-types",{"text":19,"url":20},"Explication technique des LoRa sur Hugging Face","https://huggingface.co/docs/diffusers/main/en/training/lora",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"LoRa : Modificateurs de Style Légers. Une LoRa (Low-Rank Adaptation) est un petit fichier qui applique des modifications ciblées à un modèle de point de contrôle complet, sans l'altérer de façon permanente. Pensez à une LoRa comme à un ensemble d'instructions supplémentaires ou à un filtre transparent que vous placez sur le \"cerveau\" principal (le point de contrôle) pour lui faire adopter un style spécifique, reproduire un personnage ou un concept. L'avantage principal des LoRa est leur taille réduite. Alors qu'un point de contrôle complet peut peser plusieurs gigaoctets, une LoRa ne pèse généralement que quelques mégaoctets (de 2 à 200 Mo). Cela les rend faciles à télécharger, à partager et à utiliser. Comment fonctionnent-elles ?; Au lieu de ré-entraîner l'ensemble du modèle (un processus coûteux), une LoRa est entraînée pour \"intercepter\" et modifier seulement une petite partie des poids de l'UNet et de l'Encodeur de Texte. Lorsque vous appliquez une LoRa, ses petits poids sont ajoutés à ceux du modèle principal pendant la génération, influençant le résultat final. Types courants de LoRa; Les LoRa sont incroyablement polyvalentes et peuvent être entraînées à des fins diverses : 1. Style (LoRa de Style) : Ces LoRa enseignent au modèle un style artistique spécifique (par exemple, \"style Ghibli\", \"pixel art\", \"peinture à l'huile baroque\"). Elles sont parmi les plus populaires. 2. Personnage (LoRa de Personnage) : Entraînées sur des images d'un personnage spécifique (réel ou fictif), elles permettent d'insérer ce personnage dans n'importe quelle scène avec une bonne cohérence. 3. Concept (LoRa de Concept) : Elles peuvent enseigner au modèle un concept plus abstrait, comme une pose particulière, un type de vêtement ou un objet spécifique. Utilisation dans ComfyUI; Dans ComfyUI, les LoRa sont chargées via un nœud `Load LoRA` qui s'insère généralement entre le `Load Checkpoint` et le `KSampler`. Ce nœud prend en entrée le modèle et le CLIP du point de contrôle et renvoie une version \"modifiée\" des deux, prête à être utilisée dans le reste du flux de travail. Il est également possible de combiner plusieurs LoRa (un processus appelé empilement), en appliquant différents filtres en séquence, bien que cela puisse conduire à des résultats imprévisibles si les LoRa entrent en conflit les unes avec les autres."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
