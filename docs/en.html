<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		
		<!-- 
			English: A comprehensive set of favicon links for different platforms (Apple, standard browsers) and the web manifest for PWA capabilities.
			Italiano: Un set completo di link per le favicon per diverse piattaforme (Apple, browser standard) e il web manifest per le funzionalità PWA.
		-->
		<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
		<link rel="manifest" href="/site.webmanifest">
		
		<!-- 
			English: Sets the viewport to ensure the site is responsive and scales correctly on all devices.
			Italiano: Imposta il viewport per assicurare che il sito sia responsivo e si adatti correttamente a tutti i dispositivi.
		-->
		<meta name="viewport" content="width=device-width, initial-scale=1" />

		<!-- 
			English: SvelteKit placeholder. This is where SvelteKit injects all necessary head content, like CSS links and meta tags from `svelte:head`.
			Italiano: Segnaposto di SvelteKit. Qui è dove SvelteKit inietta tutto il contenuto necessario per l'head, come i link CSS e i meta tag da `svelte:head`.
		-->
		
		<link href="./_app/immutable/assets/0.CHJcp1PB.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.CQW7PVBU.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DdPt9bVq.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/B-icdhcA.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Dv9Va7Iy.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.BRxldS8A.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/PPVm8Dsz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DsnmJJEf.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BGc_5KK-.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/C7sTqTmI.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DUX4vovL.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BU9Ixn5H.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.AQxqvBRY.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/ctJiNxf1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D2fIjOlU.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BfGA2QYN.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Cmlm8h2R.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D5MSuBSp.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/C8S6TabI.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D40XMBwt.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.CJIju4Kh.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/4.BnQ6RqHl.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/B-twNWt6.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/AGRw3LU9.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BoPAQx1w.js"><!--[--><meta name="description" content="Core Foundation Guide: un manuale interattivo e una guida di riferimento per i concetti fondamentali dell'intelligenza artificiale."/>  <meta property="og:type" content="website"/> <meta property="og:url" content="http://sveltekit-prerender/en"/> <meta property="og:title" content="Home | Core Foundation Guide"/> <meta property="og:description" content="Core Foundation Guide: un manuale interattivo e una guida di riferimento per i concetti fondamentali dell'intelligenza artificiale."/>  <meta property="twitter:card" content="summary_large_image"/> <meta property="twitter:url" content="http://sveltekit-prerender/en"/> <meta property="twitter:title" content="Home | Core Foundation Guide"/> <meta property="twitter:description" content="Core Foundation Guide: un manuale interattivo e una guida di riferimento per i concetti fondamentali dell'intelligenza artificiale."/><!--]--><title>Home | Core Foundation Guide</title>
	</head>
	<!-- 
		English: SvelteKit attribute to enable data preloading on mouse hover over links, making navigation feel faster.
		Italiano: Attributo di SvelteKit per abilitare il precaricamento dei dati al passaggio del mouse sui link, rendendo la navigazione più veloce.
	-->
	<body data-sveltekit-preload-data="hover">
		<!-- 
			English: SvelteKit placeholder for the main application body. The `display: contents` wrapper makes the div itself layout-neutral.
			Italiano: Segnaposto di SvelteKit per il corpo principale dell'applicazione. Il wrapper `display: contents` rende il div stesso neutro a livello di layout.
		-->
		<div style="display: contents"><!--[--><!--[--><!----><div class="fixed top-0 left-0 w-full h-full -z-10"></div><!----> <div class="relative z-10 isolate"><header class="fixed left-0 right-0 top-0 z-[60] w-full border-b border-cyan-900/50 bg-black/30 px-4 py-3 backdrop-blur-md md:px-8"><div class="mx-auto flex max-w-7xl items-center justify-between"><div class="flex flex-shrink-0 items-center"><a href="#" target="_blank" rel="noopener noreferrer" aria-label="Core Foundation Guide GitHub Repository" class="transition-all duration-300 hover:scale-110 hover:drop-shadow-[0_0_8px_theme(colors.amber.400)] focus:scale-110 focus:outline-none"><img src="/logo.webp" alt="Logo" class="h-10 w-10 md:h-12 md:w-12"/></a> <div class="ml-3 min-w-0 text-xl font-bold tracking-wide text-slate-200 sm:ml-4 sm:text-2xl md:ml-6 md:text-3xl lg:text-4xl"><!--[--><!--[!--><span class="char-span inline-block text-amber-400 char-highlighted">C</span><!--]--><!--[!--><span class="char-span inline-block ">O</span><!--]--><!--[!--><span class="char-span inline-block ">R</span><!--]--><!--[!--><span class="char-span inline-block ">E</span><!--]--><!--[--><span class="char-span"> </span><!--]--><!--[!--><span class="char-span inline-block text-amber-400 char-highlighted">F</span><!--]--><!--[!--><span class="char-span inline-block ">O</span><!--]--><!--[!--><span class="char-span inline-block ">U</span><!--]--><!--[!--><span class="char-span inline-block ">N</span><!--]--><!--[!--><span class="char-span inline-block ">D</span><!--]--><!--[!--><span class="char-span inline-block ">A</span><!--]--><!--[!--><span class="char-span inline-block ">T</span><!--]--><!--[!--><span class="char-span inline-block ">I</span><!--]--><!--[!--><span class="char-span inline-block ">O</span><!--]--><!--[!--><span class="char-span inline-block ">N</span><!--]--><!--[--><span class="char-span"> </span><!--]--><!--[!--><span class="char-span inline-block text-amber-400 char-highlighted">G</span><!--]--><!--[!--><span class="char-span inline-block ">U</span><!--]--><!--[!--><span class="char-span inline-block ">I</span><!--]--><!--[!--><span class="char-span inline-block ">D</span><!--]--><!--[!--><span class="char-span inline-block ">E</span><!--]--><!--]--></div></div> <svg class="hidden"><symbol id="icon-globe" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></symbol></svg> <div class="relative"><button aria-label="Change language" class="text-slate-400 transition-colors hover:text-white"><svg class="w-6 h-6"><use href="#icon-globe"></use></svg></button> <!--[!--><!--]--></div><!----></div></header><!----> <div class="flex min-h-screen flex-col pt-20"><main class="flex-grow"><!--[--><!--[--><!----><!--[--><!----><!---->  <div class="pt-8 text-center"><button class="relative inline-flex items-center gap-3 overflow-hidden rounded-lg border-2 border-slate-700 bg-slate-900/50 px-6 py-3 font-semibold text-slate-300 transition-colors hover:border-amber-400 hover:text-white"><span class="shine-effect absolute inset-0 -skew-x-[15deg] bg-gradient-to-r from-transparent via-white/30 to-transparent"></span> <span class="relative inline-flex items-center gap-3"><!--[!--><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polygon points="1 6 1 22 8 18 16 22 23 18 23 2 16 6 8 2 1 6"></polygon><line x1="8" x2="8" y1="2" y2="18"></line><line x1="16" x2="16" y1="6" y2="22"></line></svg> <span>Show Content Map</span><!--]--></span></button></div>  <!--[!--><!--]-->  <section class="px-4 pt-8 text-center md:mb-6"><div class="mx-auto max-w-lg"><input type="text" value="" placeholder="Search articles..." class="w-full rounded-lg border-2 border-slate-700 bg-slate-900/50 px-4 py-2 text-white placeholder-slate-500 transition-all focus:outline-none focus:ring-2 focus:ring-cyan-400"/></div> <div class="mt-6 flex flex-wrap items-center justify-center gap-x-4 gap-y-3"><!--[--><label class="flex cursor-pointer items-center gap-2 rounded-lg border-2 border-transparent p-2 transition-all hover:bg-slate-800/50 has[:checked]:border-amber-500 has-[:checked]:bg-amber-900/30 has-[:checked]:shadow-[0_0_15px_theme(colors.amber.500/0.4)]"><input type="checkbox" value="fundamentals" class="h-4 w-4 appearance-none rounded-sm border-2 border-slate-600 bg-slate-700 transition checked:border-transparent checked:bg-amber-500 focus:ring-2 focus:ring-amber-400 focus:ring-offset-0"/> <span class="text-sm font-medium text-slate-300 transition-colors has-[:checked]:text-white">Fundamentals</span></label><label class="flex cursor-pointer items-center gap-2 rounded-lg border-2 border-transparent p-2 transition-all hover:bg-slate-800/50 has[:checked]:border-amber-500 has-[:checked]:bg-amber-900/30 has-[:checked]:shadow-[0_0_15px_theme(colors.amber.500/0.4)]"><input type="checkbox" value="advanced-topics" class="h-4 w-4 appearance-none rounded-sm border-2 border-slate-600 bg-slate-700 transition checked:border-transparent checked:bg-amber-500 focus:ring-2 focus:ring-amber-400 focus:ring-offset-0"/> <span class="text-sm font-medium text-slate-300 transition-colors has-[:checked]:text-white">Advanced Topics</span></label><label class="flex cursor-pointer items-center gap-2 rounded-lg border-2 border-transparent p-2 transition-all hover:bg-slate-800/50 has[:checked]:border-amber-500 has-[:checked]:bg-amber-900/30 has-[:checked]:shadow-[0_0_15px_theme(colors.amber.500/0.4)]"><input type="checkbox" value="core-concepts" class="h-4 w-4 appearance-none rounded-sm border-2 border-slate-600 bg-slate-700 transition checked:border-transparent checked:bg-amber-500 focus:ring-2 focus:ring-amber-400 focus:ring-offset-0"/> <span class="text-sm font-medium text-slate-300 transition-colors has-[:checked]:text-white">Core Concepts</span></label><label class="flex cursor-pointer items-center gap-2 rounded-lg border-2 border-transparent p-2 transition-all hover:bg-slate-800/50 has[:checked]:border-amber-500 has-[:checked]:bg-amber-900/30 has-[:checked]:shadow-[0_0_15px_theme(colors.amber.500/0.4)]"><input type="checkbox" value="system-anatomy" class="h-4 w-4 appearance-none rounded-sm border-2 border-slate-600 bg-slate-700 transition checked:border-transparent checked:bg-amber-500 focus:ring-2 focus:ring-amber-400 focus:ring-offset-0"/> <span class="text-sm font-medium text-slate-300 transition-colors has-[:checked]:text-white">System Anatomy</span></label><!--]--></div></section>  <div class="mx-auto max-w-7xl px-4 pb-12"><div class="isolate grid grid-cols-2 gap-4 sm:gap-5 md:grid-cols-3 lg:grid-cols-4 xl:grid-cols-5"><!--[--><div data-slug="attention" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Attention: The Focusing Mechanism</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Attention</strong> (or <em>Self-Attention</em>) is the computational mechanism at the heart of the <strong>Transformer</strong> architecture, which has revolutionized both lan...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Advanced Topics</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="dit" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">DiT: Diffusion Transformers</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>A <strong>DiT (Diffusion Transformer)</strong> is a new architecture for diffusion models that <strong>replaces the traditional UNet with a Transformer</strong>. [1] It is an e...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Advanced Topics</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="gguf" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">GGUF: Quantization for CPU and GPU</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>GGUF (Georgi Gerganov Universal Format)</strong> is a file format designed to contain <strong>quantized</strong> neural models, that is, converted into very low-precisi...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Advanced Topics</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="llm" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">LLM: Large Language Models</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>An <strong>LLM (Large Language Model)</strong> is a type of neural network trained on massive amounts of text data (books, articles, code, conversations) with the ...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Advanced Topics</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="precision" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Precision: FP32, FP16, FP8, FP4 and the Role of the GPU</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>precision</strong> of a model refers to the numerical format used to store its &quot;weights&quot;. These weights are real numbers, and computers represent them ...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Advanced Topics</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="tokens" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Tokens: The Building Blocks of Language</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Tokens</strong> are the fundamental units into which a text is broken down before being processed by a language model like CLIP. [1] They are the &quot;building...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Advanced Topics</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="cfg" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">CFG: The Guidance Scale</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>CFG (Classifier-Free Guidance) Scale</strong> is one of the most powerful parameters at your disposal. In simple terms, it&#39;s a knob that controls **how...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="denoise" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Denoise: The Strength of Transformation</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>Denoise</strong> (or <em>denoising strength</em>) parameter is a knob that controls <strong>how much of the starting image should be transformed</strong> during the genera...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="prompt" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Prompt: Dialoguing with the AI</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>Prompt</strong> is the textual instruction you provide to the model to describe the image you want to create. It&#39;s the most direct way to dialogue with...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="sampler" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Sampler: The Denoising Technique</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>Sampler</strong> is the algorithm that actually performs the &quot;denoising&quot; process at each step. [1] If the AI model is the brain that predicts the noise...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="scheduler" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Scheduler: The Denoising Plan</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>Scheduler</strong> is the algorithm that defines the <strong>strategy</strong> and <strong>pace</strong> of the denoising process. [1] If the Sampler is the <em>technique</em> with whi...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="seed" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Seed: The Control of Randomness</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>Seed</strong> is a number that initializes the state of randomness for the generation of an image. Think of it as the <strong>unique identification code</strong> of...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="steps" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Steps: The Sampling Steps</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Steps</strong> (or sampling steps) indicate how many times the model &quot;refines&quot; the image starting from pure noise. It is one of the most important paramete...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Core Concepts</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="deep_learning" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Deep Learning: The Deep Learning</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Deep Learning</strong> is a subcategory of Machine Learning based on <strong>Deep Artificial Neural Networks</strong>, that is, neural networks with many hidden layers ...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Fundamentals</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="inference" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Inference: Using the Trained Model</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Inference</strong> is the process of <strong>using an already trained neural network</strong> to make predictions on new and unseen data. [1]</p>
<p>If <strong>training</strong> is the &quot;s...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Fundamentals</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="neural_network" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Neural Network: The Artificial Brain</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>An <strong>Artificial Neural Network</strong> is a computational model inspired by the structure and functioning of the human brain. [1] It is the fundamental buil...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>Fundamentals</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="checkpoint" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Checkpoint: The Brain of the Model</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The term <strong>Checkpoint</strong> (or <em>Model</em>) refers to the files that contain the &quot;weights&quot; of the neural network, that is, the <strong>trained brain</strong> of the artif...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="clip" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">CLIP Text Encoder: The Prompt Translator</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>CLIP (Contrastive Language-Image Pre-training)</strong> is a neural model developed by OpenAI that has revolutionized how AIs &quot;understand&quot; the relationship...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="conditioning" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Conditioning: The Instructions for the UNet</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Conditioning</strong> is the technical term that describes the <strong>guidance data</strong> that is provided to the UNet to influence and control the image generation...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="controlnet" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">ControlNet: Guiding the AI with Images</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>ControlNet</strong> is a neural network architecture that allows <strong>conditioning and controlling diffusion models using a visual input</strong>, such as an image o...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="embedding" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Embedding (Textual Inversion): Teaching New Concepts</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>An <strong>Embedding</strong>, also known as <strong>Textual Inversion</strong>, is a small file that teaches the model a <strong>new visual concept</strong> by associating it with a specif...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="inpaint" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Inpainting &amp; Outpainting: Modifying and Extending Images</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Inpainting</strong> and <strong>Outpainting</strong> are two powerful techniques that use diffusion models not to create an image from scratch, but to **modify or exten...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="latent" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Latent Space: The Compressed World of Images</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>Latent Space</strong> is a compressed and low-resolution representation of an image. It is an intermediate &quot;world&quot; in which diffusion models like Stabl...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="lora" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">LoRa: Lightweight Style Modifiers</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>A <strong>LoRa (Low-Rank Adaptation)</strong> is a small file that applies targeted modifications to a full checkpoint model, without permanently altering it. [1] ...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="segmentation" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">Segmentation: Understanding the Scene</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p><strong>Image Segmentation</strong> is a Computer Vision process that consists of <strong>partitioning an image into multiple segments or regions</strong>, associating each pix...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="unet" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">UNet: The Heart of Denoising</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>UNet</strong> is the central and most important component of a diffusion model like Stable Diffusion. It is the neural network that learns to **progres...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><div data-slug="vae" class="card-container aspect-square cursor-pointer" role="button" tabindex="0"><div class="relative h-full w-full rounded-xl bg-gradient-to-br from-cyan-950/20 to-slate-950/10 backdrop-blur-lg border-2 card-border shadow-lg card-shadow grid grid-rows-[auto_1fr_auto] border-cyan-500/30 group-hover:border-amber-400/80 shadow-cyan-900/50 group-hover:shadow-amber-500/20"><div class="p-4 pb-3 md:p-5 md:pb-4"><h2 class="font-bold text-gray-100 text-base card-title group-hover:text-amber-400">VAE: The Visual Decoder</h2></div>  <div class="relative overflow-hidden border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"><div class="p-4 pt-3 md:p-5 md:pt-4 h-full"><!--[--><div class="text-gray-400 leading-snug prose prose-sm prose-invert prose-p:text-gray-400 prose-strong:text-amber-400"><!----><p>The <strong>VAE (Variational Autoencoder)</strong> is the final decoder of your system. [1, 2]</p>
<p>Imagine that the AI model does not &quot;think&quot; with images, but in an a...</p>
<!----></div><!--]--></div> <div class="absolute inset-x-0 bottom-0 h-12 bg-gradient-to-t from-slate-950/60 to-transparent pointer-events-none"></div></div>  <div><div class="border-t card-divider border-cyan-500/20 group-hover:border-amber-400/30"></div> <div class="p-3 text-right text-xs font-semibold card-category-text text-cyan-400 group-hover:text-amber-500 flex items-center justify-end gap-2"><span>System Anatomy</span> <div class="w-2 h-2 rounded-full card-category-dot bg-cyan-400 group-hover:bg-amber-500"></div></div></div></div><!----></div><!--]--></div><!----> <!--[!--><!--]--></div><!----><!--]--><!----><!--]--><!--]--></main> <svg class="hidden"><symbol id="icon-github" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.91 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></symbol></svg> <footer class="w-full border-t border-cyan-900/50 bg-black/30 px-4 py-6 backdrop-blur-md md:px-8"><div class="mx-auto flex max-w-7xl flex-col items-center justify-between gap-4 sm:flex-row"><p class="text-sm text-slate-400">© 2025 Core Foundation Guide. An interactive field manual for AI concepts.</p>  <a href="#" target="_blank" rel="noopener noreferrer" aria-label="GitHub Repository" class="text-slate-400 transition-colors hover:text-white"><svg class="h-6 w-6"><use href="#icon-github"></use></svg></a></div></footer><!----></div></div><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_1erws2 = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.CQW7PVBU.js"),
						import("./_app/immutable/entry/app.BRxldS8A.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2, 4],
							data: [{type:"data",data:{translations:{it:{category:"Categoria",connections:"Collegamenti",backToHub:"Torna all'Hub",noPostsFound:"Nessun articolo trovato.",pageTitleCategory:"Categoria",initializing:"Inizializzazione...",backToArticles:"Torna agli articoli",sources:"Fonti",searchPlaceholder:"Cerca articoli...",showMap:"Mostra Mappa Contenuti",hideMap:"Nascondi Mappa",listenToArticle:"Ascolta questo articolo",playing:"In riproduzione...",paused:"In pausa",voice:"Voce"},en:{category:"Category",connections:"Connections",backToHub:"Back to Hub",noPostsFound:"No articles found.",pageTitleCategory:"Category",initializing:"Initializing...",backToArticles:"Back to articles",sources:"Sources",searchPlaceholder:"Search articles...",showMap:"Show Content Map",hideMap:"Hide Map",listenToArticle:"Listen to this article",playing:"Playing...",paused:"Paused",voice:"Voice"},fr:{category:"Catégorie",connections:"Connexions",backToHub:"Retour à l'accueil",noPostsFound:"Aucun article trouvé.",pageTitleCategory:"Catégorie",initializing:"Initialisation...",backToArticles:"Retour aux articles",sources:"Sources",searchPlaceholder:"Rechercher des articles...",showMap:"Afficher la carte du contenu",hideMap:"Masquer la carte",listenToArticle:"Écouter cet article",playing:"Lecture en cours...",paused:"En pause",voice:"Voix"},es:{category:"Categoría",connections:"Conexiones",backToHub:"Volver al inicio",noPostsFound:"No se encontraron artículos.",pageTitleCategory:"Categoría",initializing:"Inicializando...",backToArticles:"Volver a los artículos",sources:"Fuentes",searchPlaceholder:"Buscar artículos...",showMap:"Mostrar mapa de contenido",hideMap:"Ocultar mapa",listenToArticle:"Escuchar este artículo",playing:"Reproduciendo...",paused:"En pausa",voice:"Voz"},de:{category:"Kategorie",connections:"Verbindungen",backToHub:"Zurück zum Hub",noPostsFound:"Keine Artikel gefunden.",pageTitleCategory:"Kategorie",initializing:"Initialisiere...",backToArticles:"Zurück zu den Artikeln",sources:"Quellen",searchPlaceholder:"Artikel suchen...",showMap:"Inhaltsverzeichnis anzeigen",hideMap:"Verzeichnis ausblenden",listenToArticle:"Diesen Artikel anhören",playing:"Wiedergabe...",paused:"Pausiert",voice:"Stimme"},pt:{category:"Categoria",connections:"Conexões",backToHub:"Voltar ao início",noPostsFound:"Nenhum artigo encontrado.",pageTitleCategory:"Categoria",initializing:"Inicializando...",backToArticles:"Voltar aos artigos",sources:"Fontes",searchPlaceholder:"Pesquisar artigos...",showMap:"Mostrar mapa de conteúdo",hideMap:"Ocultar mapa",listenToArticle:"Ouvir este artigo",playing:"Reproduzindo...",paused:"Em pausa",voice:"Voz"}}},uses:{}},null,{type:"data",data:{lang:"en",posts:[{lang:"en",categorySlug:"advanced-topics",categoryName:"Advanced Topics",categoryColor:"cyan",slug:"attention",title:"Attention: The Focusing Mechanism",excerpt:"\u003Cp>\u003Cstrong>Attention\u003C/strong> (or \u003Cem>Self-Attention\u003C/em>) is the computational mechanism at the heart of the \u003Cstrong>Transformer\u003C/strong> architecture, which has revolutionized both lan...\u003C/p>\n",plainExcerpt:"Attention (or Self-Attention) is the computational mechanism at the heart of the Transformer architecture, which has revolutionized both lan..."},{lang:"en",categorySlug:"advanced-topics",categoryName:"Advanced Topics",categoryColor:"cyan",slug:"dit",title:"DiT: Diffusion Transformers",excerpt:"\u003Cp>A \u003Cstrong>DiT (Diffusion Transformer)\u003C/strong> is a new architecture for diffusion models that \u003Cstrong>replaces the traditional UNet with a Transformer\u003C/strong>. [1] It is an e...\u003C/p>\n",plainExcerpt:"A DiT (Diffusion Transformer) is a new architecture for diffusion models that replaces the traditional UNet with a Transformer. [1] It is an e..."},{lang:"en",categorySlug:"advanced-topics",categoryName:"Advanced Topics",categoryColor:"cyan",slug:"gguf",title:"GGUF: Quantization for CPU and GPU",excerpt:"\u003Cp>\u003Cstrong>GGUF (Georgi Gerganov Universal Format)\u003C/strong> is a file format designed to contain \u003Cstrong>quantized\u003C/strong> neural models, that is, converted into very low-precisi...\u003C/p>\n",plainExcerpt:"GGUF (Georgi Gerganov Universal Format) is a file format designed to contain quantized neural models, that is, converted into very low-precisi..."},{lang:"en",categorySlug:"advanced-topics",categoryName:"Advanced Topics",categoryColor:"cyan",slug:"llm",title:"LLM: Large Language Models",excerpt:"\u003Cp>An \u003Cstrong>LLM (Large Language Model)\u003C/strong> is a type of neural network trained on massive amounts of text data (books, articles, code, conversations) with the ...\u003C/p>\n",plainExcerpt:"An LLM (Large Language Model) is a type of neural network trained on massive amounts of text data (books, articles, code, conversations) with the ..."},{lang:"en",categorySlug:"advanced-topics",categoryName:"Advanced Topics",categoryColor:"cyan",slug:"precision",title:"Precision: FP32, FP16, FP8, FP4 and the Role of the GPU",excerpt:"\u003Cp>The \u003Cstrong>precision\u003C/strong> of a model refers to the numerical format used to store its &quot;weights&quot;. These weights are real numbers, and computers represent them ...\u003C/p>\n",plainExcerpt:"The precision of a model refers to the numerical format used to store its \"weights\". These weights are real numbers, and computers represent them ..."},{lang:"en",categorySlug:"advanced-topics",categoryName:"Advanced Topics",categoryColor:"cyan",slug:"tokens",title:"Tokens: The Building Blocks of Language",excerpt:"\u003Cp>\u003Cstrong>Tokens\u003C/strong> are the fundamental units into which a text is broken down before being processed by a language model like CLIP. [1] They are the &quot;building...\u003C/p>\n",plainExcerpt:"Tokens are the fundamental units into which a text is broken down before being processed by a language model like CLIP. [1] They are the \"building..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"cfg",title:"CFG: The Guidance Scale",excerpt:"\u003Cp>The \u003Cstrong>CFG (Classifier-Free Guidance) Scale\u003C/strong> is one of the most powerful parameters at your disposal. In simple terms, it&#39;s a knob that controls **how...\u003C/p>\n",plainExcerpt:"The CFG (Classifier-Free Guidance) Scale is one of the most powerful parameters at your disposal. In simple terms, it's a knob that controls how..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"denoise",title:"Denoise: The Strength of Transformation",excerpt:"\u003Cp>The \u003Cstrong>Denoise\u003C/strong> (or \u003Cem>denoising strength\u003C/em>) parameter is a knob that controls \u003Cstrong>how much of the starting image should be transformed\u003C/strong> during the genera...\u003C/p>\n",plainExcerpt:"The Denoise (or denoising strength) parameter is a knob that controls how much of the starting image should be transformed during the genera..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"prompt",title:"Prompt: Dialoguing with the AI",excerpt:"\u003Cp>The \u003Cstrong>Prompt\u003C/strong> is the textual instruction you provide to the model to describe the image you want to create. It&#39;s the most direct way to dialogue with...\u003C/p>\n",plainExcerpt:"The Prompt is the textual instruction you provide to the model to describe the image you want to create. It's the most direct way to dialogue with..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"sampler",title:"Sampler: The Denoising Technique",excerpt:"\u003Cp>The \u003Cstrong>Sampler\u003C/strong> is the algorithm that actually performs the &quot;denoising&quot; process at each step. [1] If the AI model is the brain that predicts the noise...\u003C/p>\n",plainExcerpt:"The Sampler is the algorithm that actually performs the \"denoising\" process at each step. [1] If the AI model is the brain that predicts the noise..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"scheduler",title:"Scheduler: The Denoising Plan",excerpt:"\u003Cp>The \u003Cstrong>Scheduler\u003C/strong> is the algorithm that defines the \u003Cstrong>strategy\u003C/strong> and \u003Cstrong>pace\u003C/strong> of the denoising process. [1] If the Sampler is the \u003Cem>technique\u003C/em> with whi...\u003C/p>\n",plainExcerpt:"The Scheduler is the algorithm that defines the strategy and pace of the denoising process. [1] If the Sampler is the technique with whi..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"seed",title:"Seed: The Control of Randomness",excerpt:"\u003Cp>The \u003Cstrong>Seed\u003C/strong> is a number that initializes the state of randomness for the generation of an image. Think of it as the \u003Cstrong>unique identification code\u003C/strong> of...\u003C/p>\n",plainExcerpt:"The Seed is a number that initializes the state of randomness for the generation of an image. Think of it as the unique identification code of..."},{lang:"en",categorySlug:"core-concepts",categoryName:"Core Concepts",categoryColor:"amber",slug:"steps",title:"Steps: The Sampling Steps",excerpt:"\u003Cp>\u003Cstrong>Steps\u003C/strong> (or sampling steps) indicate how many times the model &quot;refines&quot; the image starting from pure noise. It is one of the most important paramete...\u003C/p>\n",plainExcerpt:"Steps (or sampling steps) indicate how many times the model \"refines\" the image starting from pure noise. It is one of the most important paramete..."},{lang:"en",categorySlug:"fundamentals",categoryName:"Fundamentals",categoryColor:"sky",slug:"deep_learning",title:"Deep Learning: The Deep Learning",excerpt:"\u003Cp>\u003Cstrong>Deep Learning\u003C/strong> is a subcategory of Machine Learning based on \u003Cstrong>Deep Artificial Neural Networks\u003C/strong>, that is, neural networks with many hidden layers ...\u003C/p>\n",plainExcerpt:"Deep Learning is a subcategory of Machine Learning based on Deep Artificial Neural Networks, that is, neural networks with many hidden layers ..."},{lang:"en",categorySlug:"fundamentals",categoryName:"Fundamentals",categoryColor:"sky",slug:"inference",title:"Inference: Using the Trained Model",excerpt:"\u003Cp>\u003Cstrong>Inference\u003C/strong> is the process of \u003Cstrong>using an already trained neural network\u003C/strong> to make predictions on new and unseen data. [1]\u003C/p>\n\u003Cp>If \u003Cstrong>training\u003C/strong> is the &quot;s...\u003C/p>\n",plainExcerpt:"Inference is the process of using an already trained neural network to make predictions on new and unseen data. [1]\n\nIf training is the \"s..."},{lang:"en",categorySlug:"fundamentals",categoryName:"Fundamentals",categoryColor:"sky",slug:"neural_network",title:"Neural Network: The Artificial Brain",excerpt:"\u003Cp>An \u003Cstrong>Artificial Neural Network\u003C/strong> is a computational model inspired by the structure and functioning of the human brain. [1] It is the fundamental buil...\u003C/p>\n",plainExcerpt:"An Artificial Neural Network is a computational model inspired by the structure and functioning of the human brain. [1] It is the fundamental buil..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"checkpoint",title:"Checkpoint: The Brain of the Model",excerpt:"\u003Cp>The term \u003Cstrong>Checkpoint\u003C/strong> (or \u003Cem>Model\u003C/em>) refers to the files that contain the &quot;weights&quot; of the neural network, that is, the \u003Cstrong>trained brain\u003C/strong> of the artif...\u003C/p>\n",plainExcerpt:"The term Checkpoint (or Model) refers to the files that contain the \"weights\" of the neural network, that is, the trained brain of the artif..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"clip",title:"CLIP Text Encoder: The Prompt Translator",excerpt:"\u003Cp>\u003Cstrong>CLIP (Contrastive Language-Image Pre-training)\u003C/strong> is a neural model developed by OpenAI that has revolutionized how AIs &quot;understand&quot; the relationship...\u003C/p>\n",plainExcerpt:"CLIP (Contrastive Language-Image Pre-training) is a neural model developed by OpenAI that has revolutionized how AIs \"understand\" the relationship..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"conditioning",title:"Conditioning: The Instructions for the UNet",excerpt:"\u003Cp>\u003Cstrong>Conditioning\u003C/strong> is the technical term that describes the \u003Cstrong>guidance data\u003C/strong> that is provided to the UNet to influence and control the image generation...\u003C/p>\n",plainExcerpt:"Conditioning is the technical term that describes the guidance data that is provided to the UNet to influence and control the image generation..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"controlnet",title:"ControlNet: Guiding the AI with Images",excerpt:"\u003Cp>\u003Cstrong>ControlNet\u003C/strong> is a neural network architecture that allows \u003Cstrong>conditioning and controlling diffusion models using a visual input\u003C/strong>, such as an image o...\u003C/p>\n",plainExcerpt:"ControlNet is a neural network architecture that allows conditioning and controlling diffusion models using a visual input, such as an image o..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"embedding",title:"Embedding (Textual Inversion): Teaching New Concepts",excerpt:"\u003Cp>An \u003Cstrong>Embedding\u003C/strong>, also known as \u003Cstrong>Textual Inversion\u003C/strong>, is a small file that teaches the model a \u003Cstrong>new visual concept\u003C/strong> by associating it with a specif...\u003C/p>\n",plainExcerpt:"An Embedding, also known as Textual Inversion, is a small file that teaches the model a new visual concept by associating it with a specif..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"inpaint",title:"Inpainting & Outpainting: Modifying and Extending Images",excerpt:"\u003Cp>\u003Cstrong>Inpainting\u003C/strong> and \u003Cstrong>Outpainting\u003C/strong> are two powerful techniques that use diffusion models not to create an image from scratch, but to **modify or exten...\u003C/p>\n",plainExcerpt:"Inpainting and Outpainting are two powerful techniques that use diffusion models not to create an image from scratch, but to modify or exten..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"latent",title:"Latent Space: The Compressed World of Images",excerpt:"\u003Cp>The \u003Cstrong>Latent Space\u003C/strong> is a compressed and low-resolution representation of an image. It is an intermediate &quot;world&quot; in which diffusion models like Stabl...\u003C/p>\n",plainExcerpt:"The Latent Space is a compressed and low-resolution representation of an image. It is an intermediate \"world\" in which diffusion models like Stabl..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"lora",title:"LoRa: Lightweight Style Modifiers",excerpt:"\u003Cp>A \u003Cstrong>LoRa (Low-Rank Adaptation)\u003C/strong> is a small file that applies targeted modifications to a full checkpoint model, without permanently altering it. [1] ...\u003C/p>\n",plainExcerpt:"A LoRa (Low-Rank Adaptation) is a small file that applies targeted modifications to a full checkpoint model, without permanently altering it. [1] ..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"segmentation",title:"Segmentation: Understanding the Scene",excerpt:"\u003Cp>\u003Cstrong>Image Segmentation\u003C/strong> is a Computer Vision process that consists of \u003Cstrong>partitioning an image into multiple segments or regions\u003C/strong>, associating each pix...\u003C/p>\n",plainExcerpt:"Image Segmentation is a Computer Vision process that consists of partitioning an image into multiple segments or regions, associating each pix..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"unet",title:"UNet: The Heart of Denoising",excerpt:"\u003Cp>The \u003Cstrong>UNet\u003C/strong> is the central and most important component of a diffusion model like Stable Diffusion. It is the neural network that learns to **progres...\u003C/p>\n",plainExcerpt:"The UNet is the central and most important component of a diffusion model like Stable Diffusion. It is the neural network that learns to progres..."},{lang:"en",categorySlug:"system-anatomy",categoryName:"System Anatomy",categoryColor:"teal",slug:"vae",title:"VAE: The Visual Decoder",excerpt:"\u003Cp>The \u003Cstrong>VAE (Variational Autoencoder)\u003C/strong> is the final decoder of your system. [1, 2]\u003C/p>\n\u003Cp>Imagine that the AI model does not &quot;think&quot; with images, but in an a...\u003C/p>\n",plainExcerpt:"The VAE (Variational Autoencoder) is the final decoder of your system. [1, 2]\n\nImagine that the AI model does not \"think\" with images, but in an a..."}],postIndex:[{categoryName:"Fundamentals",categorySlug:"fundamentals",posts:[{title:"Deep Learning: The Deep Learning",slug:"deep_learning"},{title:"Inference: Using the Trained Model",slug:"inference"},{title:"Neural Network: The Artificial Brain",slug:"neural_network"}]},{categoryName:"System Anatomy",categorySlug:"system-anatomy",posts:[{title:"Checkpoint: The Brain of the Model",slug:"checkpoint"},{title:"CLIP Text Encoder: The Prompt Translator",slug:"clip"},{title:"Conditioning: The Instructions for the UNet",slug:"conditioning"},{title:"ControlNet: Guiding the AI with Images",slug:"controlnet"},{title:"Embedding (Textual Inversion): Teaching New Concepts",slug:"embedding"},{title:"Inpainting & Outpainting: Modifying and Extending Images",slug:"inpaint"},{title:"Latent Space: The Compressed World of Images",slug:"latent"},{title:"LoRa: Lightweight Style Modifiers",slug:"lora"},{title:"Segmentation: Understanding the Scene",slug:"segmentation"},{title:"UNet: The Heart of Denoising",slug:"unet"},{title:"VAE: The Visual Decoder",slug:"vae"}]},{categoryName:"Core Concepts",categorySlug:"core-concepts",posts:[{title:"CFG: The Guidance Scale",slug:"cfg"},{title:"Denoise: The Strength of Transformation",slug:"denoise"},{title:"Prompt: Dialoguing with the AI",slug:"prompt"},{title:"Sampler: The Denoising Technique",slug:"sampler"},{title:"Scheduler: The Denoising Plan",slug:"scheduler"},{title:"Seed: The Control of Randomness",slug:"seed"},{title:"Steps: The Sampling Steps",slug:"steps"}]},{categoryName:"Advanced Topics",categorySlug:"advanced-topics",posts:[{title:"Attention: The Focusing Mechanism",slug:"attention"},{title:"DiT: Diffusion Transformers",slug:"dit"},{title:"GGUF: Quantization for CPU and GPU",slug:"gguf"},{title:"LLM: Large Language Models",slug:"llm"},{title:"Precision: FP32, FP16, FP8, FP4 and the Role of the GPU",slug:"precision"},{title:"Tokens: The Building Blocks of Language",slug:"tokens"}]}]},uses:{params:["lang"]}}],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>