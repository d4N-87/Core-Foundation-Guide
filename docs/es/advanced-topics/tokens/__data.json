{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"es","advanced-topics","Advanced Topics","cyan","tokens","Tokens: Los Bloques de Construcción del Lenguaje","\u003Cp>Los \u003Cstrong>Tokens\u003C/strong> son las unidades fundamentales en las que se descompone un texto antes de ser procesado por un modelo de lenguaje como CLIP. [1] Son lo...\u003C/p>\n","Los Tokens son las unidades fundamentales en las que se descompone un texto antes de ser procesado por un modelo de lenguaje como CLIP. [1] Son lo...","\u003Cp>Los \u003Cstrong>Tokens\u003C/strong> son las unidades fundamentales en las que se descompone un texto antes de ser procesado por un modelo de lenguaje como CLIP. [1] Son los &quot;bloques de construcción&quot; con los que el modelo lee y comprende nuestro prompt.\u003C/p>\n\u003Cp>Un token \u003Cstrong>no es necesariamente una palabra completa\u003C/strong>. El proceso de \u003Cstrong>Tokenización\u003C/strong> utiliza un vocabulario predefinido para dividir el texto en trozos que el modelo conoce. [3]\u003C/p>\n\u003Ch3>Ejemplos de Tokenización\u003C/h3>\n\u003Cp>Consideremos la palabra \u003Ccode>indescriptiblemente\u003C/code>. Un tokenizador podría descomponerla en varios tokens que conoce:\n\u003Ccode>in\u003C/code> + \u003Ccode>descript\u003C/code> + \u003Ccode>ible\u003C/code> + \u003Ccode>mente\u003C/code>\u003C/p>\n\u003Cul>\n\u003Cli>Las \u003Cstrong>palabras comunes\u003C/strong> (por ejemplo, \u003Ccode>gato\u003C/code>, \u003Ccode>el\u003C/code>, \u003Ccode>un\u003C/code>) suelen ser un único token.\u003C/li>\n\u003Cli>Las \u003Cstrong>palabras complejas o raras\u003C/strong> se descomponen en sub-palabras.\u003C/li>\n\u003Cli>Los \u003Cstrong>espacios y la puntuación\u003C/strong> se manejan como tokens separados.\u003C/li>\n\u003C/ul>\n\u003Cp>Este enfoque permite al modelo manejar un vocabulario prácticamente infinito a partir de un número finito de tokens (generalmente entre 30.000 y 50.000). [1]\u003C/p>\n\u003Ch3>El Límite de Tokens y la Evolución de los Modelos\u003C/h3>\n\u003Cp>Cada Codificador de Texto tiene un \u003Cstrong>límite máximo de tokens\u003C/strong> que puede procesar en un solo &quot;trozo&quot;. Este límite ha sido durante mucho tiempo una de las principales restricciones en la ingeniería de prompts.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cp>\u003Cstrong>Arquitecturas Antiguas (por ejemplo, Stable Diffusion 1.5, SDXL):\u003C/strong>\nEstos modelos utilizan Codificadores de Texto (CLIP) con un límite de \u003Cstrong>75 tokens\u003C/strong> por trozo. [3] Si un prompt es más largo, se divide en varios trozos, pero la comprensión del contexto entre un bloque y otro es mucho más débil. Esto ha obligado a los usuarios a concentrar los conceptos más importantes al principio del prompt.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Nuevas Arquitecturas (por ejemplo, FLUX.1):\u003C/strong>\nLos modelos de nueva generación, como \u003Cstrong>FLUX.1\u003C/strong>, están diseñados para superar esta limitación. FLUX.1 utiliza un Codificador de Texto mucho más potente (basado en T5-XXL) que ha sido entrenado específicamente para comprender prompts largos y complejos de forma nativa. [2] Esto permite una expresión mucho más natural y detallada, sin tener que preocuparse por el límite artificial de 75 tokens.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>Comprender el concepto de tokens y las limitaciones de los diferentes modelos es fundamental para escribir prompts eficaces y aprovechar al máximo las capacidades de cada arquitectura.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Introducción a la Tokenización - Hugging Face","https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt",{"text":16,"url":17},"Anuncio del modelo FLUX.1 por Black Forest Labs","https://blackforestlabs.ai/announcing-flux/",{"text":19,"url":20},"Explicación de los Tokens en el contexto de Stable Diffusion","https://stable-diffusion-art.com/token/",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"Tokens: Los Bloques de Construcción del Lenguaje. Los Tokens son las unidades fundamentales en las que se descompone un texto antes de ser procesado por un modelo de lenguaje como CLIP. Son los \"bloques de construcción\" con los que el modelo lee y comprende nuestro prompt. Un token no es necesariamente una palabra completa. El proceso de Tokenización utiliza un vocabulario predefinido para dividir el texto en trozos que el modelo conoce. Ejemplos de Tokenización; Consideremos la palabra `indescriptiblemente`. Un tokenizador podría descomponerla en varios tokens que conoce: `in` + `descript` + `ible` + `mente` - Las palabras comunes (por ejemplo, `gato`, `el`, `un`) suelen ser un único token. - Las palabras complejas o raras se descomponen en sub-palabras. - Los espacios y la puntuación se manejan como tokens separados. Este enfoque permite al modelo manejar un vocabulario prácticamente infinito a partir de un número finito de tokens (generalmente entre 30.000 y 50.000). El Límite de Tokens y la Evolución de los Modelos; Cada Codificador de Texto tiene un límite máximo de tokens que puede procesar en un solo \"trozo\". Este límite ha sido durante mucho tiempo una de las principales restricciones en la ingeniería de prompts. - Arquitecturas Antiguas (por ejemplo, Stable Diffusion 1.5, SDXL): Estos modelos utilizan Codificadores de Texto (CLIP) con un límite de 75 tokens por trozo. Si un prompt es más largo, se divide en varios trozos, pero la comprensión del contexto entre un bloque y otro es mucho más débil. Esto ha obligado a los usuarios a concentrar los conceptos más importantes al principio del prompt. - Nuevas Arquitecturas (por ejemplo, FLUX.1): Los modelos de nueva generación, como FLUX.1, están diseñados para superar esta limitación. FLUX.1 utiliza un Codificador de Texto mucho más potente (basado en T5-XXL) que ha sido entrenado específicamente para comprender prompts largos y complejos de forma nativa. Esto permite una expresión mucho más natural y detallada, sin tener que preocuparse por el límite artificial de 75 tokens. Comprender el concepto de tokens y las limitaciones de los diferentes modelos es fundamental para escribir prompts eficaces y aprovechar al máximo las capacidades de cada arquitectura."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
