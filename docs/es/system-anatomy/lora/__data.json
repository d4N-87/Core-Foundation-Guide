{"type":"data","nodes":[{"type":"data","data":[{"translations":1},{"it":2,"en":17,"fr":32,"es":46,"de":61,"pt":76},{"category":3,"connections":4,"backToHub":5,"noPostsFound":6,"pageTitleCategory":3,"initializing":7,"backToArticles":8,"sources":9,"searchPlaceholder":10,"showMap":11,"hideMap":12,"listenToArticle":13,"playing":14,"paused":15,"voice":16},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":18,"connections":19,"backToHub":20,"noPostsFound":21,"pageTitleCategory":18,"initializing":22,"backToArticles":23,"sources":24,"searchPlaceholder":25,"showMap":26,"hideMap":27,"listenToArticle":28,"playing":29,"paused":30,"voice":31},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":33,"connections":34,"backToHub":35,"noPostsFound":36,"pageTitleCategory":33,"initializing":37,"backToArticles":38,"sources":24,"searchPlaceholder":39,"showMap":40,"hideMap":41,"listenToArticle":42,"playing":43,"paused":44,"voice":45},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":47,"connections":48,"backToHub":49,"noPostsFound":50,"pageTitleCategory":47,"initializing":51,"backToArticles":52,"sources":53,"searchPlaceholder":54,"showMap":55,"hideMap":56,"listenToArticle":57,"playing":58,"paused":59,"voice":60},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":62,"connections":63,"backToHub":64,"noPostsFound":65,"pageTitleCategory":62,"initializing":66,"backToArticles":67,"sources":68,"searchPlaceholder":69,"showMap":70,"hideMap":71,"listenToArticle":72,"playing":73,"paused":74,"voice":75},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":3,"connections":77,"backToHub":78,"noPostsFound":79,"pageTitleCategory":3,"initializing":51,"backToArticles":80,"sources":81,"searchPlaceholder":82,"showMap":83,"hideMap":56,"listenToArticle":84,"playing":85,"paused":86,"voice":60},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa"],"uses":{}},null,{"type":"data","data":[{"post":1,"translations":21,"seo":107,"textContent":108},{"lang":2,"categorySlug":3,"categoryName":4,"categoryColor":5,"slug":6,"title":7,"excerpt":8,"plainExcerpt":9,"content":10,"sources":11},"es","system-anatomy","System Anatomy","teal","lora","LoRa: Modificadores de Estilo Ligeros","\u003Cp>Una \u003Cstrong>LoRa (Adaptación de Bajo Rango)\u003C/strong> es un pequeño archivo que aplica modificaciones específicas a un modelo de punto de control completo, sin alte...\u003C/p>\n","Una LoRa (Adaptación de Bajo Rango) es un pequeño archivo que aplica modificaciones específicas a un modelo de punto de control completo, sin alte...","\u003Cp>Una \u003Cstrong>LoRa (Adaptación de Bajo Rango)\u003C/strong> es un pequeño archivo que aplica modificaciones específicas a un modelo de punto de control completo, sin alterarlo permanentemente. [1] Piensa en una LoRa como un \u003Cstrong>conjunto de instrucciones adicionales\u003C/strong> o un \u003Cstrong>filtro transparente\u003C/strong> que pones sobre el &quot;cerebro&quot; principal (el punto de control) para que adopte un estilo específico, replique un personaje o un concepto. [2]\u003C/p>\n\u003Cp>La principal ventaja de las LoRa es su \u003Cstrong>tamaño reducido\u003C/strong>. Mientras que un punto de control completo puede pesar varios gigabytes, una LoRa suele pesar solo unos pocos megabytes (de 2 a 200 MB). [3] Esto las hace fáciles de descargar, compartir y utilizar.\u003C/p>\n\u003Ch3>¿Cómo funcionan?\u003C/h3>\n\u003Cp>En lugar de reentrenar todo el modelo (un proceso costoso), una LoRa se entrena para &quot;interceptar&quot; y modificar solo una pequeña parte de los pesos de la UNet y del Codificador de Texto. [3] Cuando aplicas una LoRa, sus pequeños pesos se suman a los del modelo principal durante la generación, influyendo en el resultado final.\u003C/p>\n\u003Ch3>Tipos comunes de LoRa\u003C/h3>\n\u003Cp>Las LoRa son increíblemente versátiles y pueden entrenarse para diferentes propósitos:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Estilo (LoRa de Estilo):\u003C/strong>\nEstas LoRa enseñan al modelo un estilo artístico específico (por ejemplo, &quot;estilo Ghibli&quot;, &quot;pixel art&quot;, &quot;pintura al óleo barroca&quot;). Son de las más populares. [2]\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Personaje (LoRa de Personaje):\u003C/strong>\nEntrenadas con imágenes de un personaje específico (real o de ficción), permiten insertar ese personaje en cualquier escena con una buena consistencia.\u003C/p>\n\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Concepto (LoRa de Concepto):\u003C/strong>\nPueden enseñar al modelo un concepto más abstracto, como una pose particular, un tipo de ropa o un objeto específico.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3>Uso en ComfyUI\u003C/h3>\n\u003Cp>En ComfyUI, las LoRa se cargan a través de un nodo \u003Ccode>Load LoRA\u003C/code> que normalmente se inserta entre el \u003Ccode>Load Checkpoint\u003C/code> y el \u003Ccode>KSampler\u003C/code>. Este nodo toma como entrada el modelo y el CLIP del punto de control y devuelve una versión &quot;modificada&quot; de ambos, lista para ser utilizada en el resto del flujo de trabajo.\u003C/p>\n\u003Cp>También es posible \u003Cstrong>combinar varias LoRa\u003C/strong> (un proceso llamado \u003Cem>apilamiento\u003C/em>), aplicando diferentes filtros en secuencia, aunque esto puede llevar a resultados impredecibles si las LoRa entran en conflicto entre sí.\u003C/p>\n",[12,15,18],{"text":13,"url":14},"Artículo Original: LoRA: Adaptación de Bajo Rango de Grandes Modelos de Lenguaje","https://arxiv.org/abs/2106.09685",{"text":16,"url":17},"Guía de las LoRa en Civitai","https://civitai.com/articles/8/a-guide-to-the-different-ai-model-types",{"text":19,"url":20},"Explicación técnica de las LoRa en Hugging Face","https://huggingface.co/docs/diffusers/main/en/training/lora",{"it":22,"en":37,"fr":52,"es":66,"de":81,"pt":96},{"category":23,"connections":24,"backToHub":25,"noPostsFound":26,"pageTitleCategory":23,"initializing":27,"backToArticles":28,"sources":29,"searchPlaceholder":30,"showMap":31,"hideMap":32,"listenToArticle":33,"playing":34,"paused":35,"voice":36},"Categoria","Collegamenti","Torna all'Hub","Nessun articolo trovato.","Inizializzazione...","Torna agli articoli","Fonti","Cerca articoli...","Mostra Mappa Contenuti","Nascondi Mappa","Ascolta questo articolo","In riproduzione...","In pausa","Voce",{"category":38,"connections":39,"backToHub":40,"noPostsFound":41,"pageTitleCategory":38,"initializing":42,"backToArticles":43,"sources":44,"searchPlaceholder":45,"showMap":46,"hideMap":47,"listenToArticle":48,"playing":49,"paused":50,"voice":51},"Category","Connections","Back to Hub","No articles found.","Initializing...","Back to articles","Sources","Search articles...","Show Content Map","Hide Map","Listen to this article","Playing...","Paused","Voice",{"category":53,"connections":54,"backToHub":55,"noPostsFound":56,"pageTitleCategory":53,"initializing":57,"backToArticles":58,"sources":44,"searchPlaceholder":59,"showMap":60,"hideMap":61,"listenToArticle":62,"playing":63,"paused":64,"voice":65},"Catégorie","Connexions","Retour à l'accueil","Aucun article trouvé.","Initialisation...","Retour aux articles","Rechercher des articles...","Afficher la carte du contenu","Masquer la carte","Écouter cet article","Lecture en cours...","En pause","Voix",{"category":67,"connections":68,"backToHub":69,"noPostsFound":70,"pageTitleCategory":67,"initializing":71,"backToArticles":72,"sources":73,"searchPlaceholder":74,"showMap":75,"hideMap":76,"listenToArticle":77,"playing":78,"paused":79,"voice":80},"Categoría","Conexiones","Volver al inicio","No se encontraron artículos.","Inicializando...","Volver a los artículos","Fuentes","Buscar artículos...","Mostrar mapa de contenido","Ocultar mapa","Escuchar este artículo","Reproduciendo...","En pausa","Voz",{"category":82,"connections":83,"backToHub":84,"noPostsFound":85,"pageTitleCategory":82,"initializing":86,"backToArticles":87,"sources":88,"searchPlaceholder":89,"showMap":90,"hideMap":91,"listenToArticle":92,"playing":93,"paused":94,"voice":95},"Kategorie","Verbindungen","Zurück zum Hub","Keine Artikel gefunden.","Initialisiere...","Zurück zu den Artikeln","Quellen","Artikel suchen...","Inhaltsverzeichnis anzeigen","Verzeichnis ausblenden","Diesen Artikel anhören","Wiedergabe...","Pausiert","Stimme",{"category":23,"connections":97,"backToHub":98,"noPostsFound":99,"pageTitleCategory":23,"initializing":71,"backToArticles":100,"sources":101,"searchPlaceholder":102,"showMap":103,"hideMap":76,"listenToArticle":104,"playing":105,"paused":106,"voice":80},"Conexões","Voltar ao início","Nenhum artigo encontrado.","Voltar aos artigos","Fontes","Pesquisar artigos...","Mostrar mapa de conteúdo","Ouvir este artigo","Reproduzindo...","Em pausa",{"title":7,"description":8},"LoRa: Modificadores de Estilo Ligeros. Una LoRa (Adaptación de Bajo Rango) es un pequeño archivo que aplica modificaciones específicas a un modelo de punto de control completo, sin alterarlo permanentemente. Piensa en una LoRa como un conjunto de instrucciones adicionales o un filtro transparente que pones sobre el \"cerebro\" principal (el punto de control) para que adopte un estilo específico, replique un personaje o un concepto. La principal ventaja de las LoRa es su tamaño reducido. Mientras que un punto de control completo puede pesar varios gigabytes, una LoRa suele pesar solo unos pocos megabytes (de 2 a 200 MB). Esto las hace fáciles de descargar, compartir y utilizar. ¿Cómo funcionan?; En lugar de reentrenar todo el modelo (un proceso costoso), una LoRa se entrena para \"interceptar\" y modificar solo una pequeña parte de los pesos de la UNet y del Codificador de Texto. Cuando aplicas una LoRa, sus pequeños pesos se suman a los del modelo principal durante la generación, influyendo en el resultado final. Tipos comunes de LoRa; Las LoRa son increíblemente versátiles y pueden entrenarse para diferentes propósitos: 1. Estilo (LoRa de Estilo): Estas LoRa enseñan al modelo un estilo artístico específico (por ejemplo, \"estilo Ghibli\", \"pixel art\", \"pintura al óleo barroca\"). Son de las más populares. 2. Personaje (LoRa de Personaje): Entrenadas con imágenes de un personaje específico (real o de ficción), permiten insertar ese personaje en cualquier escena con una buena consistencia. 3. Concepto (LoRa de Concepto): Pueden enseñar al modelo un concepto más abstracto, como una pose particular, un tipo de ropa o un objeto específico. Uso en ComfyUI; En ComfyUI, las LoRa se cargan a través de un nodo `Load LoRA` que normalmente se inserta entre el `Load Checkpoint` y el `KSampler`. Este nodo toma como entrada el modelo y el CLIP del punto de control y devuelve una versión \"modificada\" de ambos, lista para ser utilizada en el resto del flujo de trabajo. También es posible combinar varias LoRa (un proceso llamado apilamiento), aplicando diferentes filtros en secuencia, aunque esto puede llevar a resultados impredecibles si las LoRa entran en conflicto entre sí."],"uses":{"params":["lang","category","slug"],"parent":1}}]}
